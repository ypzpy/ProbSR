{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS']='2'\n",
    "os.environ['LD_LIBRARY_PATH']=''\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pengyu.zhang/project/superres/ProbSR/Experiment2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/pengyu.zhang/project/superres/ProbSR/Experiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import *\n",
    "from scipy.linalg import sqrtm\n",
    "from downscaling import *\n",
    "from utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pengyu.zhang/project/superres/ProbSR/Experiment2/Bicubic_Downsampling\n"
     ]
    }
   ],
   "source": [
    "%cd Bicubic_Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langevin & Training Downscale Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upscale By 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 40\n",
    "N_high = 160\n",
    "scale = 4\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_high = create_A(N_high)\n",
    "A_low = create_A(N_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_high = torch.tensor(A_high).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_high = A_high.to_sparse()\n",
    "operator = (A_high.T) * (1/prior_sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFromH5File4(\"/home/pengyu.zhang/project/superres/ProbSR/Experiment2/data/40_160_low_forcing.h5\")\n",
    "trainset = random.sample(range(0, 1000), 600)\n",
    "testset = [i for i in range(0,1000) if i not in trainset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    coefficient = random.sample(trainset,1)[0]\n",
    "    forcing = dataset[coefficient][0]\n",
    "    lr = dataset[coefficient][1]\n",
    "    \n",
    "    return forcing, lr\n",
    "\n",
    "\n",
    "def sample_p_0(x):\n",
    "    # Randomly sampling for initialisation of the Langevin dynamics\n",
    "    # prior = torch.randn(*[batch_size,1,20,20]).to(device)\n",
    "    \n",
    "    # Set the u_low_mean to the initialisation of the Langevin dynamics\n",
    "    # posterior_initial = torch.randn([N_high,N_high]).to(torch.float32)\n",
    "    # posterior_initial = torch.tensor(posterior_initial).to(device).to(torch.float32)\n",
    "    posterior_initial  = F.interpolate(x.reshape(1,1,N_low,N_low),(N_high,N_high),mode=\"bicubic\").reshape(N_high,N_high)\n",
    "    \n",
    "    return posterior_initial\n",
    "\n",
    "    \n",
    "def ula_posterior_preconditioner(z, b_high, x, G):\n",
    "    \"\"\"\n",
    "    Langevin dynamics with preconditioner\n",
    "    \"\"\"\n",
    "    z = z.clone().detach().requires_grad_(True)\n",
    "    sum = 0\n",
    "    for i in range(K):\n",
    "        # Grad log-likelihood\n",
    "        downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "        x_hat = downscaled + G(downscaled.reshape(1,1,N_low,N_low)).reshape(N_low,N_low)\n",
    "        log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "        grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "\n",
    "        # Grad prior\n",
    "        difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "        # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "        # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "        grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "        \n",
    "        # Random noise term\n",
    "        W = torch.randn(*[N_high,N_high]).to(device)\n",
    "        # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "        \n",
    "        z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "        \n",
    "        if i >= K-10:\n",
    "            sum += z\n",
    "        \n",
    "    sum /= 10\n",
    "           \n",
    "    return sum.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists\n",
      "2024-08-14 13:29:41,627 : Training for 3000 epoches and learning rate is 0.001\n",
      "Epoch: 1 Loss: tensor(368.6698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2 Loss: tensor(336.1010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 3 Loss: tensor(271.6794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 4 Loss: tensor(234.2315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 5 Loss: tensor(168.3508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 6 Loss: tensor(162.7303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 7 Loss: tensor(122.3105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 8 Loss: tensor(103.5768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 9 Loss: tensor(87.2998, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 10 Loss: tensor(82.9440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 11 Loss: tensor(77.5873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 12 Loss: tensor(1061.9368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 13 Loss: tensor(369.9913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 14 Loss: tensor(360.6029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 15 Loss: tensor(129.3175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 16 Loss: tensor(132.4452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 17 Loss: tensor(48.8760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 18 Loss: tensor(44.2791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 19 Loss: tensor(39.7873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 20 Loss: tensor(23.6850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 21 Loss: tensor(70.5308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 22 Loss: tensor(64.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 23 Loss: tensor(114.0487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 24 Loss: tensor(52.3986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 25 Loss: tensor(425.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 26 Loss: tensor(49.8615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 27 Loss: tensor(124.4139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 28 Loss: tensor(138.4744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 29 Loss: tensor(58.0971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 30 Loss: tensor(231.6284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 31 Loss: tensor(38.4126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 32 Loss: tensor(199.1134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 33 Loss: tensor(150.8520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 34 Loss: tensor(316.7467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 35 Loss: tensor(154.2859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 36 Loss: tensor(394.8835, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 37 Loss: tensor(86.6602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 38 Loss: tensor(85.0660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 39 Loss: tensor(36.6091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 40 Loss: tensor(108.1994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 41 Loss: tensor(32.6421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 42 Loss: tensor(1910.0792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 43 Loss: tensor(93.8208, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 44 Loss: tensor(189.7913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 45 Loss: tensor(692.9802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 46 Loss: tensor(450.4871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 47 Loss: tensor(313.1470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 48 Loss: tensor(150.8623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 49 Loss: tensor(190.8888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 50 Loss: tensor(113.0192, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 51 Loss: tensor(330.3976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 52 Loss: tensor(115.7787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 53 Loss: tensor(90.9972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 54 Loss: tensor(185.8657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 55 Loss: tensor(182.5823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 56 Loss: tensor(191.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 57 Loss: tensor(109.7352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 58 Loss: tensor(123.1186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 59 Loss: tensor(85.8989, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 60 Loss: tensor(178.7286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 61 Loss: tensor(120.9848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 62 Loss: tensor(76.1711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 63 Loss: tensor(359.1992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 64 Loss: tensor(32.0680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 65 Loss: tensor(418.4799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 66 Loss: tensor(41.9999, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 67 Loss: tensor(70.7979, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 68 Loss: tensor(4199.8516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 69 Loss: tensor(224.3375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 70 Loss: tensor(520.1753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 71 Loss: tensor(408.5162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 72 Loss: tensor(340.1920, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 73 Loss: tensor(238.5947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 74 Loss: tensor(102.6486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 75 Loss: tensor(196.7845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 76 Loss: tensor(141.8258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 77 Loss: tensor(238.9782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 78 Loss: tensor(39.1931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 79 Loss: tensor(46.5617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 80 Loss: tensor(28.1469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 81 Loss: tensor(48.4212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 82 Loss: tensor(92.8849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 83 Loss: tensor(21.1210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 84 Loss: tensor(296.5505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 85 Loss: tensor(20.8257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 86 Loss: tensor(22.9474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 87 Loss: tensor(16.5589, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 88 Loss: tensor(125.9433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 89 Loss: tensor(96.2345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 90 Loss: tensor(48.4396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 91 Loss: tensor(733.3525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 92 Loss: tensor(35.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 93 Loss: tensor(209.6867, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 94 Loss: tensor(147.1097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 95 Loss: tensor(145.6057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 96 Loss: tensor(42.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 97 Loss: tensor(78.0605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 98 Loss: tensor(654.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 99 Loss: tensor(1612.9113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 100 Loss: tensor(254.9828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 101 Loss: tensor(157.5209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 102 Loss: tensor(330.5428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 103 Loss: tensor(397.8613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 104 Loss: tensor(150.9758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 105 Loss: tensor(1567.1002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 106 Loss: tensor(232.3955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 107 Loss: tensor(215.4718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 108 Loss: tensor(115.0727, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 109 Loss: tensor(129.9201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 110 Loss: tensor(63.4110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 111 Loss: tensor(119.5872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 112 Loss: tensor(36.0706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 113 Loss: tensor(207.9857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 114 Loss: tensor(126.1444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 115 Loss: tensor(158.6791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 116 Loss: tensor(78.5257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 117 Loss: tensor(51.3185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 118 Loss: tensor(29.9119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 119 Loss: tensor(114.9817, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 120 Loss: tensor(28.3071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 121 Loss: tensor(44.4393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 122 Loss: tensor(59.7662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 123 Loss: tensor(60.5837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 124 Loss: tensor(17.0622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 125 Loss: tensor(11.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 126 Loss: tensor(37.0446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 127 Loss: tensor(52.2707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 128 Loss: tensor(21.4459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 129 Loss: tensor(41.2326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 130 Loss: tensor(8.1986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 131 Loss: tensor(12.2839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 132 Loss: tensor(94.1958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 133 Loss: tensor(19.6604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 134 Loss: tensor(62.1990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 135 Loss: tensor(25.7167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 136 Loss: tensor(18.7804, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 137 Loss: tensor(770.7924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 138 Loss: tensor(143.7807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 139 Loss: tensor(110.3771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 140 Loss: tensor(51.2137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 141 Loss: tensor(102.1628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 142 Loss: tensor(125.5013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 143 Loss: tensor(26.1043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 144 Loss: tensor(55.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 145 Loss: tensor(82.8151, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 146 Loss: tensor(12.6716, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 147 Loss: tensor(57.8649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 148 Loss: tensor(10.9922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 149 Loss: tensor(79.4901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 150 Loss: tensor(6.8204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 151 Loss: tensor(27.7129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 152 Loss: tensor(6.8519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 153 Loss: tensor(38.4721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 154 Loss: tensor(9.6280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 155 Loss: tensor(12.3626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 156 Loss: tensor(33.8562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 157 Loss: tensor(6.8923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 158 Loss: tensor(27.4172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 159 Loss: tensor(34.3223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 160 Loss: tensor(38.4714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 161 Loss: tensor(601.8986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 162 Loss: tensor(7.8117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 163 Loss: tensor(35.5947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 164 Loss: tensor(51.2864, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 165 Loss: tensor(10.8256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 166 Loss: tensor(42.0741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 167 Loss: tensor(40.7052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 168 Loss: tensor(18.1459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 169 Loss: tensor(25.3935, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 170 Loss: tensor(37.6278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 171 Loss: tensor(11.8235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 172 Loss: tensor(5.2954, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 173 Loss: tensor(9.6803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 174 Loss: tensor(5.3358, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 175 Loss: tensor(4.2022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 176 Loss: tensor(147.8361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 177 Loss: tensor(67.5905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 178 Loss: tensor(11.8598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 179 Loss: tensor(20.1226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 180 Loss: tensor(19.4227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 181 Loss: tensor(638.1656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 182 Loss: tensor(223.1272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 183 Loss: tensor(40.2149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 184 Loss: tensor(150.4290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 185 Loss: tensor(82.3147, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 186 Loss: tensor(73.3404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 187 Loss: tensor(539.0080, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 188 Loss: tensor(44.7898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 189 Loss: tensor(32.2733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 190 Loss: tensor(56.2493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 191 Loss: tensor(57.9157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 192 Loss: tensor(68.4558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 193 Loss: tensor(11.8098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 194 Loss: tensor(16.8073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 195 Loss: tensor(73.0918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 196 Loss: tensor(57.6558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 197 Loss: tensor(3.6663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 198 Loss: tensor(11.5234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 199 Loss: tensor(41.1009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 200 Loss: tensor(18.6698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 201 Loss: tensor(9.8825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 202 Loss: tensor(13.3624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 203 Loss: tensor(14.5562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 204 Loss: tensor(19.1673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 205 Loss: tensor(8.2970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 206 Loss: tensor(74.4641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 207 Loss: tensor(145.6465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 208 Loss: tensor(5.8489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 209 Loss: tensor(106.3977, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 210 Loss: tensor(123.0847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 211 Loss: tensor(132.6367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 212 Loss: tensor(226.8361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 213 Loss: tensor(90.7117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 214 Loss: tensor(13.7759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 215 Loss: tensor(43.8236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 216 Loss: tensor(18.6208, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 217 Loss: tensor(20.8323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 218 Loss: tensor(151.2936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 219 Loss: tensor(21.0414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 220 Loss: tensor(24.8676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 221 Loss: tensor(13.2342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 222 Loss: tensor(26.3411, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 223 Loss: tensor(19.3980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 224 Loss: tensor(34.6722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 225 Loss: tensor(42.5728, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 226 Loss: tensor(21.3738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 227 Loss: tensor(221.0237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 228 Loss: tensor(89.4232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 229 Loss: tensor(58.7810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 230 Loss: tensor(39.4283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 231 Loss: tensor(6.9313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 232 Loss: tensor(37.6025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 233 Loss: tensor(63.3896, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 234 Loss: tensor(61.1011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 235 Loss: tensor(18.8201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 236 Loss: tensor(16.5128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 237 Loss: tensor(16.1743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 238 Loss: tensor(21.4908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 239 Loss: tensor(38.5684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 240 Loss: tensor(9.0451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 241 Loss: tensor(24.7722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 242 Loss: tensor(30.2113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 243 Loss: tensor(25.5141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 244 Loss: tensor(74.0699, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 245 Loss: tensor(162.7260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 246 Loss: tensor(26.3307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 247 Loss: tensor(32.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 248 Loss: tensor(191.2859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 249 Loss: tensor(143.8031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 250 Loss: tensor(1378.6881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 251 Loss: tensor(7.9434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 252 Loss: tensor(6.8186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 253 Loss: tensor(193.9582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 254 Loss: tensor(452.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 255 Loss: tensor(17.6368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 256 Loss: tensor(26.8676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 257 Loss: tensor(23.9091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 258 Loss: tensor(89.5082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 259 Loss: tensor(44.6784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 260 Loss: tensor(154.4715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 261 Loss: tensor(16.6530, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 262 Loss: tensor(33.0735, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 263 Loss: tensor(33.3662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 264 Loss: tensor(113.9819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 265 Loss: tensor(31.6465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 266 Loss: tensor(24.5371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 267 Loss: tensor(35.5062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 268 Loss: tensor(31.6163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 269 Loss: tensor(9.6621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 270 Loss: tensor(4.6558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 271 Loss: tensor(96.4690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 272 Loss: tensor(16.1310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 273 Loss: tensor(16.7184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 274 Loss: tensor(114.7921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 275 Loss: tensor(13.8192, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 276 Loss: tensor(14.0996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 277 Loss: tensor(233.9024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 278 Loss: tensor(87.3463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 279 Loss: tensor(19.4639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 280 Loss: tensor(42.0673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 281 Loss: tensor(25.3484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 282 Loss: tensor(2.8003, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 283 Loss: tensor(4.7534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 284 Loss: tensor(22.7479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 285 Loss: tensor(22.6772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 286 Loss: tensor(7.2361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 287 Loss: tensor(5.7205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 288 Loss: tensor(30.9212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 289 Loss: tensor(30.7979, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 290 Loss: tensor(80.7469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 291 Loss: tensor(95.9355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 292 Loss: tensor(65.0628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 293 Loss: tensor(8.9652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 294 Loss: tensor(6.6575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 295 Loss: tensor(21.0534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 296 Loss: tensor(27.3809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 297 Loss: tensor(215.3185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 298 Loss: tensor(8.3422, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 299 Loss: tensor(26.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 300 Loss: tensor(15.4447, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 301 Loss: tensor(2.9958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 302 Loss: tensor(4.9046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 303 Loss: tensor(19.7787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 304 Loss: tensor(28.6718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 305 Loss: tensor(2.4877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 306 Loss: tensor(19.2758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 307 Loss: tensor(41.5240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 308 Loss: tensor(10.2404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 309 Loss: tensor(15.0795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 310 Loss: tensor(119.6065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 311 Loss: tensor(70.5423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 312 Loss: tensor(12.1766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 313 Loss: tensor(35.2129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 314 Loss: tensor(8.4388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 315 Loss: tensor(35.3194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 316 Loss: tensor(274.6627, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 317 Loss: tensor(5.5957, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 318 Loss: tensor(8.4047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 319 Loss: tensor(11.3834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 320 Loss: tensor(188.9695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 321 Loss: tensor(8.6186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 322 Loss: tensor(31.7567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 323 Loss: tensor(23.1546, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 324 Loss: tensor(5.1516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 325 Loss: tensor(4.9949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 326 Loss: tensor(266.2789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 327 Loss: tensor(10.3555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 328 Loss: tensor(24.7049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 329 Loss: tensor(23.1000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 330 Loss: tensor(76.3685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 331 Loss: tensor(8.4350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 332 Loss: tensor(18.9819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 333 Loss: tensor(28.8015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 334 Loss: tensor(23.2150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 335 Loss: tensor(7.0145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 336 Loss: tensor(6.9461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 337 Loss: tensor(13.9384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 338 Loss: tensor(3.5871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 339 Loss: tensor(113.6201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 340 Loss: tensor(11.9088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 341 Loss: tensor(956.7809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 342 Loss: tensor(31.7658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 343 Loss: tensor(150.1745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 344 Loss: tensor(19.7642, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 345 Loss: tensor(34.4567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 346 Loss: tensor(105.4984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 347 Loss: tensor(552.7990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 348 Loss: tensor(62.9768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 349 Loss: tensor(38.1022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 350 Loss: tensor(9.8598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 351 Loss: tensor(35.3053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 352 Loss: tensor(2624.7119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 353 Loss: tensor(8.5206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 354 Loss: tensor(23.6096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 355 Loss: tensor(32.8547, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 356 Loss: tensor(67.3138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 357 Loss: tensor(75.8577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 358 Loss: tensor(2143.1885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 359 Loss: tensor(73.3053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 360 Loss: tensor(35.1329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 361 Loss: tensor(20.2757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 362 Loss: tensor(215.5128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 363 Loss: tensor(79.5751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 364 Loss: tensor(219.2707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 365 Loss: tensor(51.1962, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 366 Loss: tensor(21.6442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 367 Loss: tensor(26.9413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 368 Loss: tensor(147.0926, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 369 Loss: tensor(22.3952, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 370 Loss: tensor(37.9385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 371 Loss: tensor(19.8844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 372 Loss: tensor(219.0684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 373 Loss: tensor(9.7786, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 374 Loss: tensor(8.9970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 375 Loss: tensor(70.1290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 376 Loss: tensor(9.7429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 377 Loss: tensor(12.5954, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 378 Loss: tensor(12.8712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 379 Loss: tensor(13.3793, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 380 Loss: tensor(29.0476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 381 Loss: tensor(10.3698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 382 Loss: tensor(181.6172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 383 Loss: tensor(100.8705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 384 Loss: tensor(33.9040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 385 Loss: tensor(50.9363, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 386 Loss: tensor(95.8189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 387 Loss: tensor(24.1002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 388 Loss: tensor(495.5380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 389 Loss: tensor(1446.2072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 390 Loss: tensor(716.6786, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 391 Loss: tensor(401.2420, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 392 Loss: tensor(87.8384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 393 Loss: tensor(130.0915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 394 Loss: tensor(59.5841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 395 Loss: tensor(74.3613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 396 Loss: tensor(369.1192, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 397 Loss: tensor(102.4336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 398 Loss: tensor(33.0895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 399 Loss: tensor(39.8923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 400 Loss: tensor(19.3854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 401 Loss: tensor(212.4188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 402 Loss: tensor(19.6151, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 403 Loss: tensor(50.6412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 404 Loss: tensor(22.2504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 405 Loss: tensor(10.1166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 406 Loss: tensor(90.3044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 407 Loss: tensor(42.1846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 408 Loss: tensor(15.2568, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 409 Loss: tensor(44.8438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 410 Loss: tensor(52.6135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 411 Loss: tensor(52.4826, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 412 Loss: tensor(31.8284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 413 Loss: tensor(114.2210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 414 Loss: tensor(141.1114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 415 Loss: tensor(23.9237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 416 Loss: tensor(35.2731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 417 Loss: tensor(299.8263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 418 Loss: tensor(11.0414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 419 Loss: tensor(25.4374, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 420 Loss: tensor(23.0267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 421 Loss: tensor(19.5506, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 422 Loss: tensor(61.4634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 423 Loss: tensor(37.6942, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 424 Loss: tensor(13.1565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 425 Loss: tensor(8.0663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 426 Loss: tensor(221.1728, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 427 Loss: tensor(10.2290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 428 Loss: tensor(18.6568, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 429 Loss: tensor(23.9082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 430 Loss: tensor(43.3648, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 431 Loss: tensor(35.5466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 432 Loss: tensor(17.8248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 433 Loss: tensor(43.8449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 434 Loss: tensor(53.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 435 Loss: tensor(17.5496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 436 Loss: tensor(19.5652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 437 Loss: tensor(47.8388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 438 Loss: tensor(51.2554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 439 Loss: tensor(54.4474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 440 Loss: tensor(42.6362, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 441 Loss: tensor(17.7426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 442 Loss: tensor(52.7718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 443 Loss: tensor(46.7194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 444 Loss: tensor(21.3691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 445 Loss: tensor(38.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 446 Loss: tensor(20.7241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 447 Loss: tensor(20.3320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 448 Loss: tensor(29.4838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 449 Loss: tensor(5.7218, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 450 Loss: tensor(107.8032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 451 Loss: tensor(12.2057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 452 Loss: tensor(32.8461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 453 Loss: tensor(21.9577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 454 Loss: tensor(11.2010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 455 Loss: tensor(14.1738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 456 Loss: tensor(31.1232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 457 Loss: tensor(11.8201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 458 Loss: tensor(38.1877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 459 Loss: tensor(18.5909, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 460 Loss: tensor(82.1275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 461 Loss: tensor(4.6442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 462 Loss: tensor(15.3544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 463 Loss: tensor(65.9674, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 464 Loss: tensor(10.9240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 465 Loss: tensor(15.0347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 466 Loss: tensor(7.1369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 467 Loss: tensor(3.1488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 468 Loss: tensor(11.9448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 469 Loss: tensor(311.1141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 470 Loss: tensor(133.9981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 471 Loss: tensor(8.4847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 472 Loss: tensor(12.5696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 473 Loss: tensor(42.5784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 474 Loss: tensor(6.4624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 475 Loss: tensor(100.1414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 476 Loss: tensor(26.4603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 477 Loss: tensor(58.3285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 478 Loss: tensor(1440.5790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 479 Loss: tensor(41.8252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 480 Loss: tensor(32.1733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 481 Loss: tensor(32.1910, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 482 Loss: tensor(35.8460, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 483 Loss: tensor(44.3373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 484 Loss: tensor(13.2206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 485 Loss: tensor(21.7235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 486 Loss: tensor(9.6639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 487 Loss: tensor(28.2388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 488 Loss: tensor(207.2863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 489 Loss: tensor(42.2933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 490 Loss: tensor(23.6900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 491 Loss: tensor(20.6226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 492 Loss: tensor(11.5993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 493 Loss: tensor(13.9517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 494 Loss: tensor(50.3709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 495 Loss: tensor(75.8862, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 496 Loss: tensor(15.9175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 497 Loss: tensor(51.5534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 498 Loss: tensor(19.5544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 499 Loss: tensor(10.8711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 500 Loss: tensor(9.2879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 501 Loss: tensor(2314.1082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 502 Loss: tensor(170.1723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 503 Loss: tensor(62.8578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 504 Loss: tensor(3.7154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 505 Loss: tensor(13.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 506 Loss: tensor(50.3897, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 507 Loss: tensor(5.9862, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 508 Loss: tensor(72.1481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 509 Loss: tensor(75.1022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 510 Loss: tensor(13.7604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 511 Loss: tensor(42.1780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 512 Loss: tensor(12.1924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 513 Loss: tensor(18.4990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 514 Loss: tensor(22.9149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 515 Loss: tensor(66.0898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 516 Loss: tensor(6.4491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 517 Loss: tensor(70.7939, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 518 Loss: tensor(4.3827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 519 Loss: tensor(25.7037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 520 Loss: tensor(10.4440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 521 Loss: tensor(511.9343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 522 Loss: tensor(19.2081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 523 Loss: tensor(7.5648, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 524 Loss: tensor(12.0249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 525 Loss: tensor(66.3090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 526 Loss: tensor(24.9770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 527 Loss: tensor(94.6747, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 528 Loss: tensor(17.7431, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 529 Loss: tensor(11.8013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 530 Loss: tensor(7.5543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 531 Loss: tensor(9.8137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 532 Loss: tensor(8.1203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 533 Loss: tensor(62.5139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 534 Loss: tensor(48.3950, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 535 Loss: tensor(24.5543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 536 Loss: tensor(66.5531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 537 Loss: tensor(106.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 538 Loss: tensor(6.1263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 539 Loss: tensor(8.1701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 540 Loss: tensor(11.6660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 541 Loss: tensor(20.2569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 542 Loss: tensor(22.5672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 543 Loss: tensor(30.5145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 544 Loss: tensor(13.3878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 545 Loss: tensor(16.1601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 546 Loss: tensor(33.6150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 547 Loss: tensor(21.6477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 548 Loss: tensor(58.4517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 549 Loss: tensor(12.7259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 550 Loss: tensor(23.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 551 Loss: tensor(16.3004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 552 Loss: tensor(33.1382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 553 Loss: tensor(22.9393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 554 Loss: tensor(5.0176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 555 Loss: tensor(15.9591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 556 Loss: tensor(14.1154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 557 Loss: tensor(23.2419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 558 Loss: tensor(5.3696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 559 Loss: tensor(40.3307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 560 Loss: tensor(153.9987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 561 Loss: tensor(30.7413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 562 Loss: tensor(51.3621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 563 Loss: tensor(45.3167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 564 Loss: tensor(40.1378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 565 Loss: tensor(159.4603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 566 Loss: tensor(6.1516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 567 Loss: tensor(10.4823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 568 Loss: tensor(37.6410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 569 Loss: tensor(64.4267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 570 Loss: tensor(19.1396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 571 Loss: tensor(12.5790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 572 Loss: tensor(4905.4917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 573 Loss: tensor(13.7564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 574 Loss: tensor(8.7349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 575 Loss: tensor(51.9335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 576 Loss: tensor(6.5396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 577 Loss: tensor(16.6124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 578 Loss: tensor(11.2679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 579 Loss: tensor(440.6685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 580 Loss: tensor(17.8878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 581 Loss: tensor(22.5938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 582 Loss: tensor(20.5142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 583 Loss: tensor(16.6847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 584 Loss: tensor(19.5314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 585 Loss: tensor(35.3234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 586 Loss: tensor(69.1898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 587 Loss: tensor(12.4754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 588 Loss: tensor(34.4630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 589 Loss: tensor(7.4142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 590 Loss: tensor(34.5492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 591 Loss: tensor(5.9150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 592 Loss: tensor(777.9614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 593 Loss: tensor(11.8540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 594 Loss: tensor(34.9902, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 595 Loss: tensor(51.7775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 596 Loss: tensor(13.0806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 597 Loss: tensor(26.6630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 598 Loss: tensor(39.0247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 599 Loss: tensor(12.7941, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 600 Loss: tensor(80.3502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 601 Loss: tensor(33.9469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 602 Loss: tensor(31.6095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 603 Loss: tensor(12.7468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 604 Loss: tensor(6.1820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 605 Loss: tensor(7.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 606 Loss: tensor(7.9073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 607 Loss: tensor(7.9679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 608 Loss: tensor(21.9119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 609 Loss: tensor(9.4333, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 610 Loss: tensor(34.8058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 611 Loss: tensor(109.4483, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 612 Loss: tensor(56.6916, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 613 Loss: tensor(17.4697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 614 Loss: tensor(10.8486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 615 Loss: tensor(11.9139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 616 Loss: tensor(37.7663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 617 Loss: tensor(14.1903, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 618 Loss: tensor(23.5010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 619 Loss: tensor(8.0186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 620 Loss: tensor(23.4539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 621 Loss: tensor(12.7484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 622 Loss: tensor(9.2071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 623 Loss: tensor(16.4393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 624 Loss: tensor(9.7263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 625 Loss: tensor(48.9700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 626 Loss: tensor(16.3502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 627 Loss: tensor(5.7593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 628 Loss: tensor(40.7874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 629 Loss: tensor(2.9349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 630 Loss: tensor(23.8135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 631 Loss: tensor(13.3993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 632 Loss: tensor(20.2554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 633 Loss: tensor(11.1925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 634 Loss: tensor(11.3155, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 635 Loss: tensor(4.8262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 636 Loss: tensor(54.2797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 637 Loss: tensor(6.4958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 638 Loss: tensor(34.7457, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 639 Loss: tensor(14.4283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 640 Loss: tensor(5.1949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 641 Loss: tensor(14.8489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 642 Loss: tensor(47.4905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 643 Loss: tensor(9.0573, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 644 Loss: tensor(8.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 645 Loss: tensor(266.6603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 646 Loss: tensor(17.8583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 647 Loss: tensor(79.9278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 648 Loss: tensor(43.3638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 649 Loss: tensor(11.5555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 650 Loss: tensor(71.7444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 651 Loss: tensor(14.1335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 652 Loss: tensor(8.2891, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 653 Loss: tensor(4.1925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 654 Loss: tensor(86.2865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 655 Loss: tensor(37.5694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 656 Loss: tensor(7.3478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 657 Loss: tensor(31.9688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 658 Loss: tensor(17.0526, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 659 Loss: tensor(28.1046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 660 Loss: tensor(23.9356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 661 Loss: tensor(23.5005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 662 Loss: tensor(14.4987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 663 Loss: tensor(18.2920, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 664 Loss: tensor(46.9593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 665 Loss: tensor(6.1776, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 666 Loss: tensor(21.1177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 667 Loss: tensor(66.5343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 668 Loss: tensor(8.9960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 669 Loss: tensor(131.6530, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 670 Loss: tensor(23.2712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 671 Loss: tensor(21.1745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 672 Loss: tensor(15.3075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 673 Loss: tensor(7.9749, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 674 Loss: tensor(18.6963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 675 Loss: tensor(35.3827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 676 Loss: tensor(20.6386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 677 Loss: tensor(199.3290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 678 Loss: tensor(13.4731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 679 Loss: tensor(22.3381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 680 Loss: tensor(3.8247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 681 Loss: tensor(9.5028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 682 Loss: tensor(3.8666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 683 Loss: tensor(50.6801, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 684 Loss: tensor(109.6542, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 685 Loss: tensor(25.8657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 686 Loss: tensor(18.2666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 687 Loss: tensor(195.2640, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 688 Loss: tensor(79.6052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 689 Loss: tensor(17.8395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 690 Loss: tensor(17.9742, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 691 Loss: tensor(21.7551, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 692 Loss: tensor(23.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 693 Loss: tensor(23.0086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 694 Loss: tensor(4.5339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 695 Loss: tensor(15.9551, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 696 Loss: tensor(2.5737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 697 Loss: tensor(5.2582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 698 Loss: tensor(212.5183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 699 Loss: tensor(61.1053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 700 Loss: tensor(188.7882, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 701 Loss: tensor(6.5799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 702 Loss: tensor(12.7322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 703 Loss: tensor(6.1085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 704 Loss: tensor(4.8580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 705 Loss: tensor(6.2178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 706 Loss: tensor(19.7558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 707 Loss: tensor(10.6385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 708 Loss: tensor(8.2405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 709 Loss: tensor(21.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 710 Loss: tensor(5.2799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 711 Loss: tensor(9.9472, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 712 Loss: tensor(12.8564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 713 Loss: tensor(12.5423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 714 Loss: tensor(26.5359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 715 Loss: tensor(8.4901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 716 Loss: tensor(15.2701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 717 Loss: tensor(436.2238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 718 Loss: tensor(27.5814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 719 Loss: tensor(4.4900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 720 Loss: tensor(26.4395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 721 Loss: tensor(43.0484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 722 Loss: tensor(6.1230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 723 Loss: tensor(4.4690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 724 Loss: tensor(13.7367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 725 Loss: tensor(7.3930, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 726 Loss: tensor(7.4965, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 727 Loss: tensor(31.0267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 728 Loss: tensor(186.8947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 729 Loss: tensor(6.4408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 730 Loss: tensor(6.0975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 731 Loss: tensor(57.7788, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 732 Loss: tensor(66.8285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 733 Loss: tensor(6.9330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 734 Loss: tensor(111.7647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 735 Loss: tensor(9.1069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 736 Loss: tensor(36.2571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 737 Loss: tensor(82.5091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 738 Loss: tensor(4.5983, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 739 Loss: tensor(475.7312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 740 Loss: tensor(32.8617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 741 Loss: tensor(254.0442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 742 Loss: tensor(6.2095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 743 Loss: tensor(143.2230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 744 Loss: tensor(20.9534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 745 Loss: tensor(6.3004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 746 Loss: tensor(8.7821, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 747 Loss: tensor(23.7368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 748 Loss: tensor(74.1675, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 749 Loss: tensor(5.8240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 750 Loss: tensor(92.6145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 751 Loss: tensor(44.9015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 752 Loss: tensor(243.2329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 753 Loss: tensor(22.2355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 754 Loss: tensor(950.9610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 755 Loss: tensor(8.4609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 756 Loss: tensor(6.8047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 757 Loss: tensor(5.8108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 758 Loss: tensor(31.6313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 759 Loss: tensor(19.9948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 760 Loss: tensor(22.6736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 761 Loss: tensor(9.1051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 762 Loss: tensor(137.8116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 763 Loss: tensor(55.5106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 764 Loss: tensor(12.3077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 765 Loss: tensor(4.7730, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 766 Loss: tensor(15.2223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 767 Loss: tensor(19.5140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 768 Loss: tensor(86.3559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 769 Loss: tensor(14.3617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 770 Loss: tensor(45.2843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 771 Loss: tensor(33.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 772 Loss: tensor(17.9239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 773 Loss: tensor(23.1060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 774 Loss: tensor(168.6051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 775 Loss: tensor(93.6720, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 776 Loss: tensor(20.3215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 777 Loss: tensor(30.5016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 778 Loss: tensor(27.2767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 779 Loss: tensor(74.4005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 780 Loss: tensor(32.2258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 781 Loss: tensor(32.4434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 782 Loss: tensor(698.9761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 783 Loss: tensor(8.4055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 784 Loss: tensor(56.2503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 785 Loss: tensor(20.6099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 786 Loss: tensor(4.9468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 787 Loss: tensor(12.2792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 788 Loss: tensor(20.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 789 Loss: tensor(172.3542, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 790 Loss: tensor(16.5877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 791 Loss: tensor(11.9734, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 792 Loss: tensor(32.7066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 793 Loss: tensor(37.6944, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 794 Loss: tensor(21.4996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 795 Loss: tensor(21.4000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 796 Loss: tensor(85.2922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 797 Loss: tensor(15.2373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 798 Loss: tensor(7.7481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 799 Loss: tensor(75.4607, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 800 Loss: tensor(104.2458, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 801 Loss: tensor(3497.5273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 802 Loss: tensor(73.9313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 803 Loss: tensor(38.0099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 804 Loss: tensor(4.8859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 805 Loss: tensor(13.8623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 806 Loss: tensor(20.4441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 807 Loss: tensor(31.4949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 808 Loss: tensor(169.0928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 809 Loss: tensor(52.4273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 810 Loss: tensor(11.7024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 811 Loss: tensor(133.9318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 812 Loss: tensor(56.3743, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 813 Loss: tensor(9.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 814 Loss: tensor(5.1655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 815 Loss: tensor(13.5961, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 816 Loss: tensor(16.3595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 817 Loss: tensor(11.6118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 818 Loss: tensor(108.8178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 819 Loss: tensor(27.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 820 Loss: tensor(15.3171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 821 Loss: tensor(5.5595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 822 Loss: tensor(16.2574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 823 Loss: tensor(12.6527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 824 Loss: tensor(26.8626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 825 Loss: tensor(19.8254, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 826 Loss: tensor(17.3661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 827 Loss: tensor(537.8199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 828 Loss: tensor(1883.4309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 829 Loss: tensor(12.3314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 830 Loss: tensor(5.6612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 831 Loss: tensor(155.3119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 832 Loss: tensor(43.7002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 833 Loss: tensor(39.1934, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 834 Loss: tensor(107.2612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 835 Loss: tensor(6.1818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 836 Loss: tensor(25.5329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 837 Loss: tensor(8.6131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 838 Loss: tensor(36.9662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 839 Loss: tensor(4.4881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 840 Loss: tensor(9.3326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 841 Loss: tensor(10.7782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 842 Loss: tensor(46.4440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 843 Loss: tensor(11.7582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 844 Loss: tensor(12.0509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 845 Loss: tensor(48.9391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 846 Loss: tensor(19.7004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 847 Loss: tensor(8.8331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 848 Loss: tensor(13.3967, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 849 Loss: tensor(19.3887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 850 Loss: tensor(45.0601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 851 Loss: tensor(28.2542, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 852 Loss: tensor(18.3303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 853 Loss: tensor(46.4204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 854 Loss: tensor(19.8900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 855 Loss: tensor(77.8753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 856 Loss: tensor(746.9496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 857 Loss: tensor(28.8110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 858 Loss: tensor(27.9968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 859 Loss: tensor(27.8232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 860 Loss: tensor(5.8150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 861 Loss: tensor(103.8774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 862 Loss: tensor(19.7432, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 863 Loss: tensor(40.4074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 864 Loss: tensor(12.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 865 Loss: tensor(24.7448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 866 Loss: tensor(3426.6211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 867 Loss: tensor(16.3381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 868 Loss: tensor(70.0498, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 869 Loss: tensor(7.5794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 870 Loss: tensor(6.6624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 871 Loss: tensor(1162.6622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 872 Loss: tensor(26.4545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 873 Loss: tensor(195.0971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 874 Loss: tensor(10.7536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 875 Loss: tensor(7.3139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 876 Loss: tensor(6.6295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 877 Loss: tensor(21.1734, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 878 Loss: tensor(9.6000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 879 Loss: tensor(155.8537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 880 Loss: tensor(5.2889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 881 Loss: tensor(5.9674, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 882 Loss: tensor(16.0320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 883 Loss: tensor(7.0515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 884 Loss: tensor(25.8834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 885 Loss: tensor(47.0256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 886 Loss: tensor(90.5649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 887 Loss: tensor(46.2886, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 888 Loss: tensor(40.1237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 889 Loss: tensor(178.5090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 890 Loss: tensor(24.6605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 891 Loss: tensor(32.5196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 892 Loss: tensor(14.0704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 893 Loss: tensor(14.4782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 894 Loss: tensor(8.2217, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 895 Loss: tensor(16.6096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 896 Loss: tensor(3.8012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 897 Loss: tensor(14.4262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 898 Loss: tensor(16.7819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 899 Loss: tensor(9.7482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 900 Loss: tensor(25.3450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 901 Loss: tensor(8.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 902 Loss: tensor(65.9730, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 903 Loss: tensor(189.6370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 904 Loss: tensor(35.0664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 905 Loss: tensor(29.4849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 906 Loss: tensor(21.1540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 907 Loss: tensor(12.1452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 908 Loss: tensor(28.7681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 909 Loss: tensor(11.6828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 910 Loss: tensor(51.2004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 911 Loss: tensor(4.1998, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 912 Loss: tensor(31.9292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 913 Loss: tensor(13.0795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 914 Loss: tensor(11.5558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 915 Loss: tensor(8.6121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 916 Loss: tensor(24.6018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 917 Loss: tensor(18.1468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 918 Loss: tensor(19.0823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 919 Loss: tensor(71.8165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 920 Loss: tensor(57.8980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 921 Loss: tensor(25.5044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 922 Loss: tensor(10.8070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 923 Loss: tensor(13.7672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 924 Loss: tensor(24.7606, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 925 Loss: tensor(354.0845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 926 Loss: tensor(95.3138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 927 Loss: tensor(46.9800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 928 Loss: tensor(11.4170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 929 Loss: tensor(7.3427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 930 Loss: tensor(110.4783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 931 Loss: tensor(4.2125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 932 Loss: tensor(3.3689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 933 Loss: tensor(66.6510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 934 Loss: tensor(4.2529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 935 Loss: tensor(44.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 936 Loss: tensor(14.5144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 937 Loss: tensor(19.9685, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 938 Loss: tensor(5.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 939 Loss: tensor(27.7370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 940 Loss: tensor(18.5117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 941 Loss: tensor(8.7115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 942 Loss: tensor(51.6413, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 943 Loss: tensor(51.1703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 944 Loss: tensor(389.0284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 945 Loss: tensor(13.8765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 946 Loss: tensor(18.4672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 947 Loss: tensor(52.9563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 948 Loss: tensor(18.8744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 949 Loss: tensor(30.9663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 950 Loss: tensor(59.7289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 951 Loss: tensor(57.0625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 952 Loss: tensor(23.8500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 953 Loss: tensor(16.5463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 954 Loss: tensor(24.9955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 955 Loss: tensor(6.5581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 956 Loss: tensor(44.6107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 957 Loss: tensor(20.5030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 958 Loss: tensor(49.4905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 959 Loss: tensor(9.8698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 960 Loss: tensor(70.4109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 961 Loss: tensor(10.7704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 962 Loss: tensor(11.2885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 963 Loss: tensor(16.9126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 964 Loss: tensor(11.4859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 965 Loss: tensor(185.6766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 966 Loss: tensor(69.0675, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 967 Loss: tensor(18.3254, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 968 Loss: tensor(46.2770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 969 Loss: tensor(23.1281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 970 Loss: tensor(102.2383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 971 Loss: tensor(35.2290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 972 Loss: tensor(19.0854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 973 Loss: tensor(8.2302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 974 Loss: tensor(12.7117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 975 Loss: tensor(7.2672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 976 Loss: tensor(37.8417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 977 Loss: tensor(10.6746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 978 Loss: tensor(118.0607, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 979 Loss: tensor(5.7636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 980 Loss: tensor(37.1634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 981 Loss: tensor(19.0661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 982 Loss: tensor(14.3481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 983 Loss: tensor(30.8695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 984 Loss: tensor(16.0843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 985 Loss: tensor(21.4027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 986 Loss: tensor(47.5898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 987 Loss: tensor(15.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 988 Loss: tensor(31.3806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 989 Loss: tensor(42.4316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 990 Loss: tensor(152.7503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 991 Loss: tensor(51.8871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 992 Loss: tensor(17.4977, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 993 Loss: tensor(381.7411, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 994 Loss: tensor(88.7834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 995 Loss: tensor(30.2156, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 996 Loss: tensor(29.5867, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 997 Loss: tensor(9.4797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 998 Loss: tensor(5.7613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 999 Loss: tensor(11.3033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1000 Loss: tensor(697.0740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1001 Loss: tensor(11.4888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1002 Loss: tensor(1529.2808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1003 Loss: tensor(97.2221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1004 Loss: tensor(6.1198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1005 Loss: tensor(79.2718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1006 Loss: tensor(18.2852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1007 Loss: tensor(12.9169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1008 Loss: tensor(68.5701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1009 Loss: tensor(18.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1010 Loss: tensor(31.0406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1011 Loss: tensor(17.8604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1012 Loss: tensor(63.6590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1013 Loss: tensor(34.4927, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1014 Loss: tensor(42.1018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1015 Loss: tensor(7.4946, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1016 Loss: tensor(39.9069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1017 Loss: tensor(18.7139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1018 Loss: tensor(7.2042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1019 Loss: tensor(6.9122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1020 Loss: tensor(263.1163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1021 Loss: tensor(36.9338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1022 Loss: tensor(370.8895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1023 Loss: tensor(8.0938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1024 Loss: tensor(3309.5718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1025 Loss: tensor(55.7527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1026 Loss: tensor(77.5751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1027 Loss: tensor(12.9160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1028 Loss: tensor(16.3471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1029 Loss: tensor(5.8398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1030 Loss: tensor(131.3221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1031 Loss: tensor(6.7505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1032 Loss: tensor(175.9313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1033 Loss: tensor(19.1750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1034 Loss: tensor(31.5229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1035 Loss: tensor(15.0808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1036 Loss: tensor(13.6670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1037 Loss: tensor(7.4614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1038 Loss: tensor(10.1241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1039 Loss: tensor(40.4921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1040 Loss: tensor(47.5851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1041 Loss: tensor(10.2949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1042 Loss: tensor(9.5969, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1043 Loss: tensor(26.4664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1044 Loss: tensor(63.6971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1045 Loss: tensor(38.5678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1046 Loss: tensor(10.4794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1047 Loss: tensor(118.9195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1048 Loss: tensor(16.5387, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1049 Loss: tensor(99.2808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1050 Loss: tensor(95.4010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1051 Loss: tensor(7.1162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1052 Loss: tensor(35.8848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1053 Loss: tensor(129.5923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1054 Loss: tensor(9.2746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1055 Loss: tensor(8.5968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1056 Loss: tensor(15.6343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1057 Loss: tensor(12.4332, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1058 Loss: tensor(33.3455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1059 Loss: tensor(6.8626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1060 Loss: tensor(96.6948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1061 Loss: tensor(10.6369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1062 Loss: tensor(19.2690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1063 Loss: tensor(16.7221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1064 Loss: tensor(18.8971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1065 Loss: tensor(16.4131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1066 Loss: tensor(91.8186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1067 Loss: tensor(28.5739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1068 Loss: tensor(15.1975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1069 Loss: tensor(38.5321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1070 Loss: tensor(25.9792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1071 Loss: tensor(88.2503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1072 Loss: tensor(28.4486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1073 Loss: tensor(22.4137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1074 Loss: tensor(93.3924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1075 Loss: tensor(10.5986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1076 Loss: tensor(41.9848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1077 Loss: tensor(12.6354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1078 Loss: tensor(612.2316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1079 Loss: tensor(25.8684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1080 Loss: tensor(22.5880, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1081 Loss: tensor(61.6282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1082 Loss: tensor(266.6632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1083 Loss: tensor(17.9061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1084 Loss: tensor(6.9926, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1085 Loss: tensor(25.7658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1086 Loss: tensor(5.9521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1087 Loss: tensor(30.6958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1088 Loss: tensor(8.1494, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1089 Loss: tensor(42.4437, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1090 Loss: tensor(63.7414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1091 Loss: tensor(3.4075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1092 Loss: tensor(8.6204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1093 Loss: tensor(13.0642, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1094 Loss: tensor(124.2680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1095 Loss: tensor(96.2319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1096 Loss: tensor(121.8232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1097 Loss: tensor(46.0155, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1098 Loss: tensor(10.5732, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1099 Loss: tensor(44.9470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1100 Loss: tensor(8.2622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1101 Loss: tensor(10.5833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1102 Loss: tensor(39.9471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1103 Loss: tensor(31.4325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1104 Loss: tensor(36.7873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1105 Loss: tensor(34.4622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1106 Loss: tensor(12.4664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1107 Loss: tensor(36.6664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1108 Loss: tensor(10.5277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1109 Loss: tensor(51.6194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1110 Loss: tensor(104.8061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1111 Loss: tensor(68.1474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1112 Loss: tensor(347.5558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1113 Loss: tensor(9.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1114 Loss: tensor(28.9063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1115 Loss: tensor(19.1994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1116 Loss: tensor(39.4852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1117 Loss: tensor(14.8430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1118 Loss: tensor(55.7377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1119 Loss: tensor(27.7095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1120 Loss: tensor(108.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1121 Loss: tensor(14.9083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1122 Loss: tensor(11.2767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1123 Loss: tensor(8.8364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1124 Loss: tensor(6.1039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1125 Loss: tensor(38.7372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1126 Loss: tensor(66.1185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1127 Loss: tensor(27.4932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1128 Loss: tensor(6.4752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1129 Loss: tensor(17.9936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1130 Loss: tensor(8.9481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1131 Loss: tensor(43.6251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1132 Loss: tensor(81.2828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1133 Loss: tensor(19.1159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1134 Loss: tensor(14.0377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1135 Loss: tensor(43.7258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1136 Loss: tensor(11.7766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1137 Loss: tensor(28.3659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1138 Loss: tensor(328.0894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1139 Loss: tensor(3.3348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1140 Loss: tensor(13.5518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1141 Loss: tensor(7.6561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1142 Loss: tensor(14.4382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1143 Loss: tensor(165.5870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1144 Loss: tensor(21.6702, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1145 Loss: tensor(22.1159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1146 Loss: tensor(8.6019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1147 Loss: tensor(67.6495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1148 Loss: tensor(7.5603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1149 Loss: tensor(176.3234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1150 Loss: tensor(10.7659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1151 Loss: tensor(115.9837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1152 Loss: tensor(29.5029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1153 Loss: tensor(32.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1154 Loss: tensor(74.3689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1155 Loss: tensor(77.2861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1156 Loss: tensor(126.8030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1157 Loss: tensor(169.6687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1158 Loss: tensor(170.8299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1159 Loss: tensor(22.6599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1160 Loss: tensor(46.4783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1161 Loss: tensor(11.4470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1162 Loss: tensor(4.1929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1163 Loss: tensor(12.7728, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1164 Loss: tensor(33.3400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1165 Loss: tensor(7.5695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1166 Loss: tensor(28.5519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1167 Loss: tensor(133.7266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1168 Loss: tensor(22.5458, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1169 Loss: tensor(84.5700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1170 Loss: tensor(86.5798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1171 Loss: tensor(7.5338, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1172 Loss: tensor(87.4056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1173 Loss: tensor(7.6805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1174 Loss: tensor(13.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1175 Loss: tensor(10.5504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1176 Loss: tensor(7.1582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1177 Loss: tensor(6.7664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1178 Loss: tensor(41.2876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1179 Loss: tensor(4.6800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1180 Loss: tensor(88.5211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1181 Loss: tensor(295.9275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1182 Loss: tensor(94.2119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1183 Loss: tensor(65.4794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1184 Loss: tensor(29.7863, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1185 Loss: tensor(16.4852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1186 Loss: tensor(72.2557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1187 Loss: tensor(7.3984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1188 Loss: tensor(8.1178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1189 Loss: tensor(22.2814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1190 Loss: tensor(78.8255, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1191 Loss: tensor(70.3865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1192 Loss: tensor(10.7760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1193 Loss: tensor(53.2012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1194 Loss: tensor(5.8049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1195 Loss: tensor(9.3628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1196 Loss: tensor(5.2458, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1197 Loss: tensor(18.9096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1198 Loss: tensor(18.2080, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1199 Loss: tensor(8.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1200 Loss: tensor(61.9240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1201 Loss: tensor(878.9796, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1202 Loss: tensor(240.6034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1203 Loss: tensor(115.2269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1204 Loss: tensor(8.9330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1205 Loss: tensor(12.4652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1206 Loss: tensor(65.1487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1207 Loss: tensor(20.3167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1208 Loss: tensor(1512.3002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1209 Loss: tensor(142.6662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1210 Loss: tensor(22.9011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1211 Loss: tensor(13.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1212 Loss: tensor(21.9774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1213 Loss: tensor(47.6886, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1214 Loss: tensor(6.9850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1215 Loss: tensor(24.9236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1216 Loss: tensor(4.8352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1217 Loss: tensor(6.8404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1218 Loss: tensor(49.3789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1219 Loss: tensor(7.2215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1220 Loss: tensor(16.7450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1221 Loss: tensor(146.4273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1222 Loss: tensor(141.5759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1223 Loss: tensor(358.9885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1224 Loss: tensor(44.3191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1225 Loss: tensor(5.5692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1226 Loss: tensor(40.1738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1227 Loss: tensor(6.8378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1228 Loss: tensor(21.4259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1229 Loss: tensor(35.0841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1230 Loss: tensor(324.6350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1231 Loss: tensor(25.3234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1232 Loss: tensor(5.5157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1233 Loss: tensor(17.5024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1234 Loss: tensor(13.6417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1235 Loss: tensor(104.3990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1236 Loss: tensor(177.8511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1237 Loss: tensor(14.9328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1238 Loss: tensor(4.1339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1239 Loss: tensor(12.3587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1240 Loss: tensor(265.3244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1241 Loss: tensor(56.7384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1242 Loss: tensor(120.4909, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1243 Loss: tensor(5.7770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1244 Loss: tensor(98.3722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1245 Loss: tensor(6.8280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1246 Loss: tensor(43.9023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1247 Loss: tensor(14.2258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1248 Loss: tensor(57.7097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1249 Loss: tensor(32.3972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1250 Loss: tensor(36.6591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1251 Loss: tensor(41.9962, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1252 Loss: tensor(5.8875, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1253 Loss: tensor(6.4493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1254 Loss: tensor(44.5465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1255 Loss: tensor(24.0305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1256 Loss: tensor(16.8072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1257 Loss: tensor(19.2908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1258 Loss: tensor(50.7884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1259 Loss: tensor(186.7683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1260 Loss: tensor(27.3949, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1261 Loss: tensor(346.9630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1262 Loss: tensor(21.5203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1263 Loss: tensor(5.7084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1264 Loss: tensor(28.5783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1265 Loss: tensor(10.6656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1266 Loss: tensor(30.2409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1267 Loss: tensor(99.4462, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1268 Loss: tensor(133.2490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1269 Loss: tensor(12.6184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1270 Loss: tensor(16.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1271 Loss: tensor(8.8091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1272 Loss: tensor(10.4260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1273 Loss: tensor(24.6380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1274 Loss: tensor(8.8365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1275 Loss: tensor(35.1299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1276 Loss: tensor(68.2106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1277 Loss: tensor(76.3629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1278 Loss: tensor(10.9463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1279 Loss: tensor(16.3350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1280 Loss: tensor(12.3982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1281 Loss: tensor(5.5993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1282 Loss: tensor(7.4394, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1283 Loss: tensor(8.1149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1284 Loss: tensor(47.6735, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1285 Loss: tensor(18.1608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1286 Loss: tensor(41.9379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1287 Loss: tensor(7.6966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1288 Loss: tensor(28.0199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1289 Loss: tensor(61.8628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1290 Loss: tensor(151.7619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1291 Loss: tensor(15.9630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1292 Loss: tensor(11.9073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1293 Loss: tensor(33.6214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1294 Loss: tensor(11.7397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1295 Loss: tensor(4.8907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1296 Loss: tensor(10.2737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1297 Loss: tensor(921.2230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1298 Loss: tensor(57.7849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1299 Loss: tensor(4.7148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1300 Loss: tensor(37.2827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1301 Loss: tensor(31.6632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1302 Loss: tensor(15.4770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1303 Loss: tensor(87.9122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1304 Loss: tensor(151.5898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1305 Loss: tensor(38.1490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1306 Loss: tensor(6.1340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1307 Loss: tensor(731.2001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1308 Loss: tensor(13.9349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1309 Loss: tensor(10.1111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1310 Loss: tensor(5.1905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1311 Loss: tensor(12.4886, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1312 Loss: tensor(78.5729, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1313 Loss: tensor(50.7037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1314 Loss: tensor(9.3250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1315 Loss: tensor(32.1265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1316 Loss: tensor(6.4758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1317 Loss: tensor(27.8376, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1318 Loss: tensor(16.9011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1319 Loss: tensor(373.8450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1320 Loss: tensor(24.5652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1321 Loss: tensor(19.7386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1322 Loss: tensor(142.2615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1323 Loss: tensor(12.8121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1324 Loss: tensor(89.2172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1325 Loss: tensor(23.9833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1326 Loss: tensor(293.1803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1327 Loss: tensor(6.9802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1328 Loss: tensor(22.5787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1329 Loss: tensor(92.4645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1330 Loss: tensor(665.8102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1331 Loss: tensor(112.6145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1332 Loss: tensor(79.8449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1333 Loss: tensor(3292.7417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1334 Loss: tensor(19.2230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1335 Loss: tensor(38.1170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1336 Loss: tensor(9.4927, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1337 Loss: tensor(12.4545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1338 Loss: tensor(46.2623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1339 Loss: tensor(141.0182, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1340 Loss: tensor(5.8105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1341 Loss: tensor(51.2612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1342 Loss: tensor(4.2202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1343 Loss: tensor(98.3219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1344 Loss: tensor(86.2445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1345 Loss: tensor(7.4165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1346 Loss: tensor(6.9267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1347 Loss: tensor(80.4842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1348 Loss: tensor(6.1423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1349 Loss: tensor(62.3157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1350 Loss: tensor(16.4597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1351 Loss: tensor(18.4230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1352 Loss: tensor(25.1631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1353 Loss: tensor(31.5518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1354 Loss: tensor(83.4298, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1355 Loss: tensor(358.2502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1356 Loss: tensor(324.0497, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1357 Loss: tensor(151.4463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1358 Loss: tensor(665.6677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1359 Loss: tensor(39.9412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1360 Loss: tensor(11.2757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1361 Loss: tensor(12.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1362 Loss: tensor(60.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1363 Loss: tensor(32.3461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1364 Loss: tensor(8.5310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1365 Loss: tensor(14.0503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1366 Loss: tensor(98.3920, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1367 Loss: tensor(24.0463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1368 Loss: tensor(16.4546, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1369 Loss: tensor(14.2288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1370 Loss: tensor(47.6565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1371 Loss: tensor(92.3559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1372 Loss: tensor(19.0650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1373 Loss: tensor(53.7847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1374 Loss: tensor(49.6814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1375 Loss: tensor(14.2226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1376 Loss: tensor(62.2405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1377 Loss: tensor(730.6301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1378 Loss: tensor(15.2187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1379 Loss: tensor(16.8613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1380 Loss: tensor(7.9427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1381 Loss: tensor(4.8335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1382 Loss: tensor(77.1536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1383 Loss: tensor(56.5967, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1384 Loss: tensor(3.3494, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1385 Loss: tensor(18.7215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1386 Loss: tensor(103.7211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1387 Loss: tensor(6.3100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1388 Loss: tensor(4.8340, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1389 Loss: tensor(114.4704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1390 Loss: tensor(10.9102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1391 Loss: tensor(10.7849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1392 Loss: tensor(7.6915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1393 Loss: tensor(35.6044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1394 Loss: tensor(120.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1395 Loss: tensor(186.3146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1396 Loss: tensor(14.7930, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1397 Loss: tensor(8.9806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1398 Loss: tensor(84.4973, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1399 Loss: tensor(18.3802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1400 Loss: tensor(37.2523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1401 Loss: tensor(7.2645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1402 Loss: tensor(4.7679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1403 Loss: tensor(43.7425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1404 Loss: tensor(26.0384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1405 Loss: tensor(15.8226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1406 Loss: tensor(88.6889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1407 Loss: tensor(123.7428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1408 Loss: tensor(14.1897, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1409 Loss: tensor(31.3598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1410 Loss: tensor(44.5706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1411 Loss: tensor(4.7298, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1412 Loss: tensor(95.8265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1413 Loss: tensor(13.6283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1414 Loss: tensor(20.7227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1415 Loss: tensor(6.9922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1416 Loss: tensor(23.2194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1417 Loss: tensor(10.8127, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1418 Loss: tensor(25.2407, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1419 Loss: tensor(5.5146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1420 Loss: tensor(8.8405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1421 Loss: tensor(15.1515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1422 Loss: tensor(27.8318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1423 Loss: tensor(16.5980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1424 Loss: tensor(29.6110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1425 Loss: tensor(26.9635, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1426 Loss: tensor(18.0492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1427 Loss: tensor(68.2441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1428 Loss: tensor(143.2167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1429 Loss: tensor(46.5143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1430 Loss: tensor(5.2011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1431 Loss: tensor(6.4717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1432 Loss: tensor(13.6602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1433 Loss: tensor(7.8388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1434 Loss: tensor(87.2789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1435 Loss: tensor(7.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1436 Loss: tensor(12.3528, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1437 Loss: tensor(4.2496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1438 Loss: tensor(4.2219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1439 Loss: tensor(89.2306, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1440 Loss: tensor(1508.9800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1441 Loss: tensor(7.4244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1442 Loss: tensor(9.1236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1443 Loss: tensor(14.9099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1444 Loss: tensor(15.9261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1445 Loss: tensor(26.0689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1446 Loss: tensor(10.5005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1447 Loss: tensor(19.2956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1448 Loss: tensor(25.9134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1449 Loss: tensor(28.2785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1450 Loss: tensor(49.6754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1451 Loss: tensor(13.6185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1452 Loss: tensor(93.5370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1453 Loss: tensor(45.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1454 Loss: tensor(17.5186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1455 Loss: tensor(873.8417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1456 Loss: tensor(24.7107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1457 Loss: tensor(51.9361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1458 Loss: tensor(145.3418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1459 Loss: tensor(17.4718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1460 Loss: tensor(10.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1461 Loss: tensor(14.9163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1462 Loss: tensor(843.4061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1463 Loss: tensor(14.7404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1464 Loss: tensor(66.3905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1465 Loss: tensor(17.7508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1466 Loss: tensor(48.4175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1467 Loss: tensor(171.3977, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1468 Loss: tensor(140.7238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1469 Loss: tensor(13.2302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1470 Loss: tensor(37.5616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1471 Loss: tensor(12.3148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1472 Loss: tensor(67.4357, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1473 Loss: tensor(6.8589, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1474 Loss: tensor(5.1052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1475 Loss: tensor(11.7161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1476 Loss: tensor(4.1577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1477 Loss: tensor(39.6592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1478 Loss: tensor(9.4196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1479 Loss: tensor(16.2231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1480 Loss: tensor(6.6475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1481 Loss: tensor(90.8757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1482 Loss: tensor(20.5873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1483 Loss: tensor(15.1113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1484 Loss: tensor(93.3596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1485 Loss: tensor(53.2295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1486 Loss: tensor(8.7737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1487 Loss: tensor(12.6426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1488 Loss: tensor(91.0330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1489 Loss: tensor(20.6583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1490 Loss: tensor(6.7605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1491 Loss: tensor(35.0657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1492 Loss: tensor(5.5853, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1493 Loss: tensor(24.0361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1494 Loss: tensor(293.2425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1495 Loss: tensor(6.9547, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1496 Loss: tensor(7.1571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1497 Loss: tensor(10.9280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1498 Loss: tensor(372.9670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1499 Loss: tensor(730.3917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1500 Loss: tensor(40.5476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1501 Loss: tensor(26.9668, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1502 Loss: tensor(18.9068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1503 Loss: tensor(621.5712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1504 Loss: tensor(5.9196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1505 Loss: tensor(4.2400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1506 Loss: tensor(10.0220, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1507 Loss: tensor(97.9709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1508 Loss: tensor(3288.2891, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1509 Loss: tensor(16.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1510 Loss: tensor(5.8831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1511 Loss: tensor(70.4477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1512 Loss: tensor(322.5836, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1513 Loss: tensor(28.5671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1514 Loss: tensor(5.2809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1515 Loss: tensor(42.0305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1516 Loss: tensor(22.8647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1517 Loss: tensor(25.9150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1518 Loss: tensor(42.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1519 Loss: tensor(161.7031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1520 Loss: tensor(70.1643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1521 Loss: tensor(18.9088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1522 Loss: tensor(7.6844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1523 Loss: tensor(10.8184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1524 Loss: tensor(135.4591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1525 Loss: tensor(106.6286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1526 Loss: tensor(14.0250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1527 Loss: tensor(4.2309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1528 Loss: tensor(16.0177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1529 Loss: tensor(99.1832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1530 Loss: tensor(21.7487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1531 Loss: tensor(47.6498, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1532 Loss: tensor(7.5953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1533 Loss: tensor(38.7193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1534 Loss: tensor(10.7181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1535 Loss: tensor(35.5990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1536 Loss: tensor(9.4539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1537 Loss: tensor(161.5595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1538 Loss: tensor(9.4448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1539 Loss: tensor(100.5240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1540 Loss: tensor(54.9555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1541 Loss: tensor(32.3549, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1542 Loss: tensor(44.6646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1543 Loss: tensor(36.7283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1544 Loss: tensor(85.2012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1545 Loss: tensor(22.3124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1546 Loss: tensor(43.9508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1547 Loss: tensor(32.6618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1548 Loss: tensor(170.9115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1549 Loss: tensor(7.3013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1550 Loss: tensor(87.8646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1551 Loss: tensor(43.6036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1552 Loss: tensor(18.1131, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1553 Loss: tensor(97.9118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1554 Loss: tensor(8.0080, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1555 Loss: tensor(7.2924, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1556 Loss: tensor(5.8309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1557 Loss: tensor(15.7296, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1558 Loss: tensor(120.0435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1559 Loss: tensor(4.4185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1560 Loss: tensor(24.8440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1561 Loss: tensor(32.6253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1562 Loss: tensor(77.4093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1563 Loss: tensor(11.5029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1564 Loss: tensor(62.4629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1565 Loss: tensor(5.8213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1566 Loss: tensor(13.8531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1567 Loss: tensor(12.8124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1568 Loss: tensor(4.2624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1569 Loss: tensor(18.4688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1570 Loss: tensor(851.3510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1571 Loss: tensor(114.1277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1572 Loss: tensor(366.0857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1573 Loss: tensor(40.4153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1574 Loss: tensor(85.2555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1575 Loss: tensor(7.8452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1576 Loss: tensor(11.7260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1577 Loss: tensor(7.6734, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1578 Loss: tensor(9.5230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1579 Loss: tensor(4.4580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1580 Loss: tensor(75.6700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1581 Loss: tensor(263.7769, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1582 Loss: tensor(4.1535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1583 Loss: tensor(7.1576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1584 Loss: tensor(27.8737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1585 Loss: tensor(16.9022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1586 Loss: tensor(55.6475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1587 Loss: tensor(6.5869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1588 Loss: tensor(15.2459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1589 Loss: tensor(72.1348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1590 Loss: tensor(76.8782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1591 Loss: tensor(26.9451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1592 Loss: tensor(7.4293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1593 Loss: tensor(32.6762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1594 Loss: tensor(474.9688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1595 Loss: tensor(29.4855, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1596 Loss: tensor(263.6936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1597 Loss: tensor(4413.7217, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1598 Loss: tensor(97.8276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1599 Loss: tensor(17.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1600 Loss: tensor(6.7245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1601 Loss: tensor(16.3993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1602 Loss: tensor(35.0144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1603 Loss: tensor(5.2654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1604 Loss: tensor(22.2956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1605 Loss: tensor(72.8781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1606 Loss: tensor(141.6937, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1607 Loss: tensor(31.7588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1608 Loss: tensor(5.2252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1609 Loss: tensor(41.3407, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1610 Loss: tensor(10.4908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1611 Loss: tensor(80.1693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1612 Loss: tensor(18.7124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1613 Loss: tensor(24.6878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1614 Loss: tensor(16.9233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1615 Loss: tensor(12.3533, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1616 Loss: tensor(26.9936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1617 Loss: tensor(66.8452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1618 Loss: tensor(16.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1619 Loss: tensor(60.2390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1620 Loss: tensor(7.5274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1621 Loss: tensor(5.8239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1622 Loss: tensor(59.6665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1623 Loss: tensor(6.8649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1624 Loss: tensor(18.9765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1625 Loss: tensor(14.4838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1626 Loss: tensor(16.4517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1627 Loss: tensor(37.2682, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1628 Loss: tensor(44.6666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1629 Loss: tensor(7.0260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1630 Loss: tensor(68.2881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1631 Loss: tensor(40.1328, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1632 Loss: tensor(45.2182, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1633 Loss: tensor(915.8657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1634 Loss: tensor(86.3947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1635 Loss: tensor(70.1178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1636 Loss: tensor(8.8650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1637 Loss: tensor(57.8014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1638 Loss: tensor(6.6724, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1639 Loss: tensor(10.3806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1640 Loss: tensor(108.6288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1641 Loss: tensor(186.9137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1642 Loss: tensor(15.4289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1643 Loss: tensor(8.4428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1644 Loss: tensor(6.9165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1645 Loss: tensor(6.9847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1646 Loss: tensor(32.7631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1647 Loss: tensor(19.0765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1648 Loss: tensor(26.9868, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1649 Loss: tensor(99.1527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1650 Loss: tensor(5.6940, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1651 Loss: tensor(915.8066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1652 Loss: tensor(7.1613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1653 Loss: tensor(169.7774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1654 Loss: tensor(7.2109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1655 Loss: tensor(170.9665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1656 Loss: tensor(53.3142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1657 Loss: tensor(19.2441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1658 Loss: tensor(21.7906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1659 Loss: tensor(100.4816, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1660 Loss: tensor(7.0163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1661 Loss: tensor(43.6438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1662 Loss: tensor(32.3051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1663 Loss: tensor(5.6278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1664 Loss: tensor(6.0517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1665 Loss: tensor(37.5000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1666 Loss: tensor(9.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1667 Loss: tensor(51.4044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1668 Loss: tensor(46.4084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1669 Loss: tensor(24.5580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1670 Loss: tensor(44.5346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1671 Loss: tensor(44.2321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1672 Loss: tensor(15.1278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1673 Loss: tensor(47.1769, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1674 Loss: tensor(16.6099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1675 Loss: tensor(17.8806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1676 Loss: tensor(16.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1677 Loss: tensor(124.5625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1678 Loss: tensor(28.3979, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1679 Loss: tensor(8.2111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1680 Loss: tensor(47.6302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1681 Loss: tensor(26.3712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1682 Loss: tensor(7.6490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1683 Loss: tensor(6.4916, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1684 Loss: tensor(43.6875, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1685 Loss: tensor(66.1897, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1686 Loss: tensor(18.0527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1687 Loss: tensor(3290.6824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1688 Loss: tensor(6.8667, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1689 Loss: tensor(43.6666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1690 Loss: tensor(12.9311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1691 Loss: tensor(47.1089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1692 Loss: tensor(119.5943, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1693 Loss: tensor(19.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1694 Loss: tensor(10.1339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1695 Loss: tensor(66.3438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1696 Loss: tensor(70.1013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1697 Loss: tensor(1506.7878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1698 Loss: tensor(17.5130, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1699 Loss: tensor(24.1516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1700 Loss: tensor(177.8639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1701 Loss: tensor(100.4736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1702 Loss: tensor(66.3479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1703 Loss: tensor(43.6510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1704 Loss: tensor(20.2899, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1705 Loss: tensor(8.8632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1706 Loss: tensor(25.2317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1707 Loss: tensor(31.4243, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1708 Loss: tensor(55.3630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1709 Loss: tensor(13.6827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1710 Loss: tensor(18.0362, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1711 Loss: tensor(10.3192, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1712 Loss: tensor(51.9452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1713 Loss: tensor(55.6410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1714 Loss: tensor(6.5882, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1715 Loss: tensor(10.3721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1716 Loss: tensor(45.0209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1717 Loss: tensor(176.0803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1718 Loss: tensor(27.6248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1719 Loss: tensor(7.5272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1720 Loss: tensor(43.6216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1721 Loss: tensor(72.8444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1722 Loss: tensor(18.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1723 Loss: tensor(6.7237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1724 Loss: tensor(291.6394, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1725 Loss: tensor(104.1330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1726 Loss: tensor(5.8077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1727 Loss: tensor(11.5024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1728 Loss: tensor(24.4128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1729 Loss: tensor(43.7507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1730 Loss: tensor(40.1183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1731 Loss: tensor(8.4401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1732 Loss: tensor(70.1752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1733 Loss: tensor(12.3549, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1734 Loss: tensor(11.2908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1735 Loss: tensor(36.6792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1736 Loss: tensor(11.7115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1737 Loss: tensor(68.2730, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1738 Loss: tensor(44.3722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1739 Loss: tensor(24.4830, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1740 Loss: tensor(664.9092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1741 Loss: tensor(55.2163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1742 Loss: tensor(10.3274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1743 Loss: tensor(91.3077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1744 Loss: tensor(19.1666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1745 Loss: tensor(18.9277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1746 Loss: tensor(37.2344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1747 Loss: tensor(30.5326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1748 Loss: tensor(33.1624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1749 Loss: tensor(34.7703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1750 Loss: tensor(13.9359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1751 Loss: tensor(7.4578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1752 Loss: tensor(12.3765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1753 Loss: tensor(15.0981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1754 Loss: tensor(40.4160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1755 Loss: tensor(24.8246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1756 Loss: tensor(14.2106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1757 Loss: tensor(29.3628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1758 Loss: tensor(176.1433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1759 Loss: tensor(17.8057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1760 Loss: tensor(6.7100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1761 Loss: tensor(850.8304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1762 Loss: tensor(96.3598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1763 Loss: tensor(46.3428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1764 Loss: tensor(5.2809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1765 Loss: tensor(21.8918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1766 Loss: tensor(12.3605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1767 Loss: tensor(114.7137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1768 Loss: tensor(15.6827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1769 Loss: tensor(32.6068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1770 Loss: tensor(100.4823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1771 Loss: tensor(22.9395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1772 Loss: tensor(31.8825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1773 Loss: tensor(87.8089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1774 Loss: tensor(151.1001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1775 Loss: tensor(38.5320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1776 Loss: tensor(8.5938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1777 Loss: tensor(19.2440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1778 Loss: tensor(17.5325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1779 Loss: tensor(10.3317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1780 Loss: tensor(30.4150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1781 Loss: tensor(9.3597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1782 Loss: tensor(11.2907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1783 Loss: tensor(10.7064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1784 Loss: tensor(4.2315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1785 Loss: tensor(19.1739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1786 Loss: tensor(17.4745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1787 Loss: tensor(55.6171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1788 Loss: tensor(20.3148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1789 Loss: tensor(18.0996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1790 Loss: tensor(9.8491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1791 Loss: tensor(15.6156, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1792 Loss: tensor(10.6984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1793 Loss: tensor(46.1850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1794 Loss: tensor(21.4881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1795 Loss: tensor(5.2888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1796 Loss: tensor(17.8029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1797 Loss: tensor(19.7090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1798 Loss: tensor(6.1582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1799 Loss: tensor(5.8519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1800 Loss: tensor(30.4021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1801 Loss: tensor(57.3670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1802 Loss: tensor(7.4386, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1803 Loss: tensor(4.2638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1804 Loss: tensor(30.5503, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1805 Loss: tensor(6.8895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1806 Loss: tensor(24.3893, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1807 Loss: tensor(70.0975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1808 Loss: tensor(28.7409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1809 Loss: tensor(87.2636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1810 Loss: tensor(19.8695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1811 Loss: tensor(19.2341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1812 Loss: tensor(14.2129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1813 Loss: tensor(13.8702, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1814 Loss: tensor(101.0237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1815 Loss: tensor(5.2805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1816 Loss: tensor(141.9076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1817 Loss: tensor(33.9834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1818 Loss: tensor(22.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1819 Loss: tensor(4.7335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1820 Loss: tensor(7.4617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1821 Loss: tensor(6.2553, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1822 Loss: tensor(11.7350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1823 Loss: tensor(141.9592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1824 Loss: tensor(53.4546, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1825 Loss: tensor(21.3578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1826 Loss: tensor(32.0356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1827 Loss: tensor(176.1183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1828 Loss: tensor(27.3887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1829 Loss: tensor(9.7829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1830 Loss: tensor(5.6256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1831 Loss: tensor(7.3183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1832 Loss: tensor(5.8903, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1833 Loss: tensor(66.6792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1834 Loss: tensor(55.8399, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1835 Loss: tensor(10.9753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1836 Loss: tensor(4.8356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1837 Loss: tensor(3.2231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1838 Loss: tensor(51.2634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1839 Loss: tensor(118.7095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1840 Loss: tensor(32.8269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1841 Loss: tensor(9.3704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1842 Loss: tensor(80.1366, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1843 Loss: tensor(169.7819, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1844 Loss: tensor(120.3725, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1845 Loss: tensor(12.3559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1846 Loss: tensor(12.0595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1847 Loss: tensor(7.3025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1848 Loss: tensor(10.6872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1849 Loss: tensor(146.7301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1850 Loss: tensor(35.5750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1851 Loss: tensor(29.5837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1852 Loss: tensor(77.4166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1853 Loss: tensor(24.8531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1854 Loss: tensor(6.9905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1855 Loss: tensor(24.4285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1856 Loss: tensor(57.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1857 Loss: tensor(13.6109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1858 Loss: tensor(365.7509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1859 Loss: tensor(30.3761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1860 Loss: tensor(31.1670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1861 Loss: tensor(135.3976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1862 Loss: tensor(31.1695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1863 Loss: tensor(16.8854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1864 Loss: tensor(25.2187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1865 Loss: tensor(89.5687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1866 Loss: tensor(24.0770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1867 Loss: tensor(34.1062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1868 Loss: tensor(10.3164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1869 Loss: tensor(17.5360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1870 Loss: tensor(7.5759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1871 Loss: tensor(72.8954, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1872 Loss: tensor(57.9440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1873 Loss: tensor(14.5015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1874 Loss: tensor(43.6354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1875 Loss: tensor(29.4128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1876 Loss: tensor(78.4873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1877 Loss: tensor(3290.3303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1878 Loss: tensor(6.8036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1879 Loss: tensor(80.4353, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1880 Loss: tensor(31.8721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1881 Loss: tensor(78.4802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1882 Loss: tensor(49.8866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1883 Loss: tensor(18.7360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1884 Loss: tensor(95.4600, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1885 Loss: tensor(24.4148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1886 Loss: tensor(44.5475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1887 Loss: tensor(27.9839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1888 Loss: tensor(87.9079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1889 Loss: tensor(44.6721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1890 Loss: tensor(75.5327, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1891 Loss: tensor(8.5996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1892 Loss: tensor(56.2722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1893 Loss: tensor(8.7602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1894 Loss: tensor(32.3348, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1895 Loss: tensor(77.9380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1896 Loss: tensor(5.8224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1897 Loss: tensor(30.7663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1898 Loss: tensor(263.4473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1899 Loss: tensor(12.0663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1900 Loss: tensor(18.9161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1901 Loss: tensor(12.7988, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1902 Loss: tensor(17.9646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1903 Loss: tensor(28.1966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1904 Loss: tensor(8.9827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1905 Loss: tensor(114.7138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1906 Loss: tensor(40.3582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1907 Loss: tensor(39.5188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1908 Loss: tensor(44.3723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1909 Loss: tensor(28.0905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1910 Loss: tensor(24.4747, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1911 Loss: tensor(24.4996, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1912 Loss: tensor(27.3955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1913 Loss: tensor(23.2723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1914 Loss: tensor(46.3522, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1915 Loss: tensor(38.4992, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1916 Loss: tensor(10.0384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1917 Loss: tensor(59.1643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1918 Loss: tensor(19.3350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1919 Loss: tensor(345.3561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1920 Loss: tensor(10.9012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1921 Loss: tensor(70.1206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1922 Loss: tensor(618.9689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1923 Loss: tensor(12.0579, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1924 Loss: tensor(15.4409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1925 Loss: tensor(10.8349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1926 Loss: tensor(53.3953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1927 Loss: tensor(291.6029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1928 Loss: tensor(12.9550, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1929 Loss: tensor(4.7367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1930 Loss: tensor(29.5322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1931 Loss: tensor(29.4777, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1932 Loss: tensor(6.0506, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1933 Loss: tensor(31.6665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1934 Loss: tensor(9.1616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1935 Loss: tensor(8.9214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1936 Loss: tensor(53.3160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1937 Loss: tensor(9.3450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1938 Loss: tensor(11.4078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1939 Loss: tensor(80.3291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1940 Loss: tensor(19.4615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1941 Loss: tensor(5.2814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1942 Loss: tensor(24.5186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1943 Loss: tensor(56.2559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1944 Loss: tensor(8.1072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1945 Loss: tensor(14.7531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1946 Loss: tensor(49.6385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1947 Loss: tensor(6.9966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1948 Loss: tensor(28.3801, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1949 Loss: tensor(4.7288, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1950 Loss: tensor(13.9759, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1951 Loss: tensor(40.4055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1952 Loss: tensor(141.8799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1953 Loss: tensor(56.5867, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1954 Loss: tensor(5.6231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1955 Loss: tensor(4.5586, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1956 Loss: tensor(74.5915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1957 Loss: tensor(8.5402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1958 Loss: tensor(24.8859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1959 Loss: tensor(31.7525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1960 Loss: tensor(6.5926, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1961 Loss: tensor(6.6519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1962 Loss: tensor(40.4137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1963 Loss: tensor(4.7318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1964 Loss: tensor(14.9370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1965 Loss: tensor(14.2309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1966 Loss: tensor(22.5674, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1967 Loss: tensor(124.9969, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1968 Loss: tensor(28.8870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1969 Loss: tensor(18.9134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1970 Loss: tensor(14.5004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1971 Loss: tensor(31.1530, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1972 Loss: tensor(8.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1973 Loss: tensor(38.2196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1974 Loss: tensor(186.2280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1975 Loss: tensor(26.1834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1976 Loss: tensor(6.7683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1977 Loss: tensor(16.4474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1978 Loss: tensor(292.6293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1979 Loss: tensor(19.4495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1980 Loss: tensor(16.9161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1981 Loss: tensor(18.6890, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1982 Loss: tensor(92.2525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1983 Loss: tensor(16.8750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1984 Loss: tensor(170.4082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1985 Loss: tensor(34.8858, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1986 Loss: tensor(26.0242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1987 Loss: tensor(114.5069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1988 Loss: tensor(43.6578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1989 Loss: tensor(6.7306, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1990 Loss: tensor(28.7000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1991 Loss: tensor(93.0807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1992 Loss: tensor(11.2713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1993 Loss: tensor(1679.2748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1994 Loss: tensor(32.0281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1995 Loss: tensor(146.7162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1996 Loss: tensor(22.8904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1997 Loss: tensor(59.7612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1998 Loss: tensor(44.3178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 1999 Loss: tensor(15.8791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2000 Loss: tensor(62.4907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2001 Loss: tensor(10.0339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2002 Loss: tensor(14.0707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2003 Loss: tensor(64.4316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2004 Loss: tensor(9.0217, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2005 Loss: tensor(100.1791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2006 Loss: tensor(5.5287, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2007 Loss: tensor(22.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2008 Loss: tensor(11.9285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2009 Loss: tensor(16.8673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2010 Loss: tensor(20.2594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2011 Loss: tensor(5.7964, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2012 Loss: tensor(10.3802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2013 Loss: tensor(10.0539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2014 Loss: tensor(13.6874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2015 Loss: tensor(8.9234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2016 Loss: tensor(9.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2017 Loss: tensor(9.4443, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2018 Loss: tensor(16.3053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2019 Loss: tensor(1796.7913, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2020 Loss: tensor(40.3712, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2021 Loss: tensor(15.9598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2022 Loss: tensor(17.0293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2023 Loss: tensor(7.4446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2024 Loss: tensor(29.5331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2025 Loss: tensor(72.1320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2026 Loss: tensor(17.8002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2027 Loss: tensor(146.7458, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2028 Loss: tensor(33.3563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2029 Loss: tensor(56.2526, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2030 Loss: tensor(19.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2031 Loss: tensor(730.1265, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2032 Loss: tensor(120.7258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2033 Loss: tensor(11.7474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2034 Loss: tensor(291.5665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2035 Loss: tensor(30.7939, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2036 Loss: tensor(60.7474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2037 Loss: tensor(32.6061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2038 Loss: tensor(28.6336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2039 Loss: tensor(40.0173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2040 Loss: tensor(47.5001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2041 Loss: tensor(14.6850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2042 Loss: tensor(33.9841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2043 Loss: tensor(12.3756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2044 Loss: tensor(16.2917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2045 Loss: tensor(39.6484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2046 Loss: tensor(98.0107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2047 Loss: tensor(15.8800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2048 Loss: tensor(17.5258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2049 Loss: tensor(841.8433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2050 Loss: tensor(5.8146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2051 Loss: tensor(4.4700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2052 Loss: tensor(7.1468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2053 Loss: tensor(7.5359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2054 Loss: tensor(9.3785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2055 Loss: tensor(36.7287, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2056 Loss: tensor(77.1035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2057 Loss: tensor(70.1275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2058 Loss: tensor(8.6349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2059 Loss: tensor(4.1019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2060 Loss: tensor(6.2722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2061 Loss: tensor(28.7147, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2062 Loss: tensor(44.2472, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2063 Loss: tensor(915.5205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2064 Loss: tensor(8.3601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2065 Loss: tensor(32.5598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2066 Loss: tensor(29.4515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2067 Loss: tensor(57.0259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2068 Loss: tensor(233.7329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2069 Loss: tensor(59.8035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2070 Loss: tensor(850.8293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2071 Loss: tensor(17.7968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2072 Loss: tensor(30.7860, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2073 Loss: tensor(9.7861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2074 Loss: tensor(31.2878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2075 Loss: tensor(38.2084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2076 Loss: tensor(60.2404, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2077 Loss: tensor(18.1107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2078 Loss: tensor(5.9187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2079 Loss: tensor(332.5557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2080 Loss: tensor(74.6107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2081 Loss: tensor(24.3661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2082 Loss: tensor(16.3859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2083 Loss: tensor(18.7185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2084 Loss: tensor(18.7210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2085 Loss: tensor(85.1771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2086 Loss: tensor(45.2466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2087 Loss: tensor(9.8628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2088 Loss: tensor(18.1491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2089 Loss: tensor(80.0500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2090 Loss: tensor(18.7359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2091 Loss: tensor(9.7749, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2092 Loss: tensor(3.3429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2093 Loss: tensor(54.8877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2094 Loss: tensor(62.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2095 Loss: tensor(6.6642, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2096 Loss: tensor(365.7631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2097 Loss: tensor(27.3936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2098 Loss: tensor(43.9086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2099 Loss: tensor(49.1186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2100 Loss: tensor(841.8270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2101 Loss: tensor(49.6134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2102 Loss: tensor(99.1595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2103 Loss: tensor(5.6915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2104 Loss: tensor(26.9753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2105 Loss: tensor(8.9154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2106 Loss: tensor(9.2987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2107 Loss: tensor(66.6839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2108 Loss: tensor(18.7172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2109 Loss: tensor(51.4023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2110 Loss: tensor(40.3392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2111 Loss: tensor(8.4451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2112 Loss: tensor(6.9135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2113 Loss: tensor(55.8661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2114 Loss: tensor(7.4314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2115 Loss: tensor(5.6464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2116 Loss: tensor(57.7564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2117 Loss: tensor(134.5077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2118 Loss: tensor(5.9606, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2119 Loss: tensor(4412.3291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2120 Loss: tensor(36.6887, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2121 Loss: tensor(899.2033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2122 Loss: tensor(7.1489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2123 Loss: tensor(15.4180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2124 Loss: tensor(92.2588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2125 Loss: tensor(7.6938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2126 Loss: tensor(19.2004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2127 Loss: tensor(14.7325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2128 Loss: tensor(8.9154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2129 Loss: tensor(50.7884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2130 Loss: tensor(44.2301, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2131 Loss: tensor(915.5086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2132 Loss: tensor(5.9598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2133 Loss: tensor(9.3604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2134 Loss: tensor(8.8399, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2135 Loss: tensor(41.4567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2136 Loss: tensor(51.9514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2137 Loss: tensor(13.7324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2138 Loss: tensor(10.7933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2139 Loss: tensor(8.3295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2140 Loss: tensor(24.0839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2141 Loss: tensor(5.3079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2142 Loss: tensor(29.3552, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2143 Loss: tensor(17.8074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2144 Loss: tensor(169.8025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2145 Loss: tensor(49.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2146 Loss: tensor(57.7478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2147 Loss: tensor(48.4107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2148 Loss: tensor(64.4250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2149 Loss: tensor(841.7757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2150 Loss: tensor(170.8828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2151 Loss: tensor(50.8789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2152 Loss: tensor(8.8180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2153 Loss: tensor(3.3514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2154 Loss: tensor(22.6639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2155 Loss: tensor(28.1980, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2156 Loss: tensor(111.7521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2157 Loss: tensor(10.5036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2158 Loss: tensor(34.6807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2159 Loss: tensor(17.2281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2160 Loss: tensor(66.9165, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2161 Loss: tensor(7.6155, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2162 Loss: tensor(8.2010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2163 Loss: tensor(8.8653, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2164 Loss: tensor(19.4538, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2165 Loss: tensor(72.3682, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2166 Loss: tensor(3.3452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2167 Loss: tensor(497.0713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2168 Loss: tensor(16.3666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2169 Loss: tensor(18.7382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2170 Loss: tensor(140.5329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2171 Loss: tensor(24.1134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2172 Loss: tensor(10.8997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2173 Loss: tensor(21.8066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2174 Loss: tensor(6.9938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2175 Loss: tensor(17.5492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2176 Loss: tensor(36.0961, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2177 Loss: tensor(100.1711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2178 Loss: tensor(10.9224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2179 Loss: tensor(17.0426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2180 Loss: tensor(44.3696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2181 Loss: tensor(22.0498, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2182 Loss: tensor(16.0160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2183 Loss: tensor(3.3349, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2184 Loss: tensor(5.2909, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2185 Loss: tensor(24.5153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2186 Loss: tensor(22.5665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2187 Loss: tensor(14.0938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2188 Loss: tensor(4.2611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2189 Loss: tensor(10.3589, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2190 Loss: tensor(6.2658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2191 Loss: tensor(28.8953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2192 Loss: tensor(108.5125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2193 Loss: tensor(32.4070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2194 Loss: tensor(41.9125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2195 Loss: tensor(14.2795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2196 Loss: tensor(12.4536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2197 Loss: tensor(170.8387, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2198 Loss: tensor(12.4693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2199 Loss: tensor(841.7612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2200 Loss: tensor(9.2596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2201 Loss: tensor(6.0524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2202 Loss: tensor(32.3505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2203 Loss: tensor(20.2879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2204 Loss: tensor(24.8488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2205 Loss: tensor(14.7618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2206 Loss: tensor(10.1283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2207 Loss: tensor(80.2917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2208 Loss: tensor(4.5641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2209 Loss: tensor(8.3313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2210 Loss: tensor(11.2678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2211 Loss: tensor(22.3180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2212 Loss: tensor(44.3556, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2213 Loss: tensor(10.1484, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2214 Loss: tensor(3290.0701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2215 Loss: tensor(60.2096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2216 Loss: tensor(6.0656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2217 Loss: tensor(36.9285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2218 Loss: tensor(12.7941, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2219 Loss: tensor(17.5576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2220 Loss: tensor(24.8638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2221 Loss: tensor(12.0495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2222 Loss: tensor(54.8889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2223 Loss: tensor(47.1420, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2224 Loss: tensor(27.5995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2225 Loss: tensor(30.3893, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2226 Loss: tensor(27.6216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2227 Loss: tensor(6.6535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2228 Loss: tensor(14.3496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2229 Loss: tensor(3.3437, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2230 Loss: tensor(51.4478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2231 Loss: tensor(57.0333, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2232 Loss: tensor(24.9085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2233 Loss: tensor(15.5475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2234 Loss: tensor(114.3450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2235 Loss: tensor(72.2264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2236 Loss: tensor(28.5776, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2237 Loss: tensor(5.8234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2238 Loss: tensor(18.0661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2239 Loss: tensor(186.7967, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2240 Loss: tensor(10.3724, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2241 Loss: tensor(5.9120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2242 Loss: tensor(915.4966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2243 Loss: tensor(14.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2244 Loss: tensor(59.1724, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2245 Loss: tensor(19.7050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2246 Loss: tensor(12.4464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2247 Loss: tensor(13.6957, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2248 Loss: tensor(18.5613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2249 Loss: tensor(32.6312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2250 Loss: tensor(11.0961, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2251 Loss: tensor(74.5908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2252 Loss: tensor(66.2180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2253 Loss: tensor(8.8207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2254 Loss: tensor(10.8304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2255 Loss: tensor(27.4093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2256 Loss: tensor(161.7951, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2257 Loss: tensor(9.7909, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2258 Loss: tensor(372.3793, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2259 Loss: tensor(4.7384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2260 Loss: tensor(41.6272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2261 Loss: tensor(5.5283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2262 Loss: tensor(17.5683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2263 Loss: tensor(6.7161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2264 Loss: tensor(5.6005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2265 Loss: tensor(7.3130, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2266 Loss: tensor(8.5453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2267 Loss: tensor(10.1436, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2268 Loss: tensor(3.3448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2269 Loss: tensor(6.9033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2270 Loss: tensor(49.4389, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2271 Loss: tensor(8.1464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2272 Loss: tensor(135.3839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2273 Loss: tensor(26.3824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2274 Loss: tensor(49.2464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2275 Loss: tensor(62.3335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2276 Loss: tensor(30.2757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2277 Loss: tensor(46.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2278 Loss: tensor(6.4359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2279 Loss: tensor(16.6094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2280 Loss: tensor(915.3931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2281 Loss: tensor(18.6652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2282 Loss: tensor(31.1537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2283 Loss: tensor(527.1877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2284 Loss: tensor(18.9740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2285 Loss: tensor(6.7199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2286 Loss: tensor(48.3989, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2287 Loss: tensor(2191.3906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2288 Loss: tensor(54.9614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2289 Loss: tensor(89.5748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2290 Loss: tensor(8.4424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2291 Loss: tensor(4.4619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2292 Loss: tensor(26.3136, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2293 Loss: tensor(56.2698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2294 Loss: tensor(126.4137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2295 Loss: tensor(119.8085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2296 Loss: tensor(14.7176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2297 Loss: tensor(12.4662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2298 Loss: tensor(28.5794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2299 Loss: tensor(15.8694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2300 Loss: tensor(44.4860, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2301 Loss: tensor(24.6417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2302 Loss: tensor(4.9257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2303 Loss: tensor(34.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2304 Loss: tensor(24.8334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2305 Loss: tensor(87.2206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2306 Loss: tensor(9.5083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2307 Loss: tensor(6.7091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2308 Loss: tensor(85.5855, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2309 Loss: tensor(44.6948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2310 Loss: tensor(12.8920, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2311 Loss: tensor(16.3905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2312 Loss: tensor(38.6326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2313 Loss: tensor(31.1655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2314 Loss: tensor(12.8827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2315 Loss: tensor(23.3176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2316 Loss: tensor(32.3501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2317 Loss: tensor(22.0903, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2318 Loss: tensor(49.2446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2319 Loss: tensor(8.9170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2320 Loss: tensor(5.1128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2321 Loss: tensor(29.5491, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2322 Loss: tensor(8.0227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2323 Loss: tensor(46.6185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2324 Loss: tensor(161.9302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2325 Loss: tensor(29.4608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2326 Loss: tensor(151.0997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2327 Loss: tensor(28.5859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2328 Loss: tensor(12.7955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2329 Loss: tensor(11.5059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2330 Loss: tensor(80.4272, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2331 Loss: tensor(93.1521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2332 Loss: tensor(10.0299, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2333 Loss: tensor(33.1599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2334 Loss: tensor(22.8116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2335 Loss: tensor(20.1872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2336 Loss: tensor(30.4612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2337 Loss: tensor(36.0654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2338 Loss: tensor(15.2026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2339 Loss: tensor(18.4270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2340 Loss: tensor(34.9580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2341 Loss: tensor(24.8137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2342 Loss: tensor(10.8177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2343 Loss: tensor(92.2465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2344 Loss: tensor(21.9099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2345 Loss: tensor(9.7752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2346 Loss: tensor(40.3523, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2347 Loss: tensor(86.3849, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2348 Loss: tensor(57.7474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2349 Loss: tensor(5.1073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2350 Loss: tensor(5.8454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2351 Loss: tensor(4.8509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2352 Loss: tensor(15.1257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2353 Loss: tensor(8.2489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2354 Loss: tensor(53.4270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2355 Loss: tensor(38.2454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2356 Loss: tensor(12.3040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2357 Loss: tensor(900.7302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2358 Loss: tensor(3.2194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2359 Loss: tensor(97.8090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2360 Loss: tensor(8.9085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2361 Loss: tensor(14.0485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2362 Loss: tensor(29.1103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2363 Loss: tensor(59.8014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2364 Loss: tensor(172.5345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2365 Loss: tensor(9.3622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2366 Loss: tensor(20.2873, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2367 Loss: tensor(12.8833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2368 Loss: tensor(27.3666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2369 Loss: tensor(100.1779, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2370 Loss: tensor(5.8439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2371 Loss: tensor(29.4739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2372 Loss: tensor(7.5795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2373 Loss: tensor(17.5459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2374 Loss: tensor(14.0569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2375 Loss: tensor(5.5308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2376 Loss: tensor(22.4854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2377 Loss: tensor(6.1570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2378 Loss: tensor(6.7182, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2379 Loss: tensor(35.4022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2380 Loss: tensor(106.4963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2381 Loss: tensor(30.1028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2382 Loss: tensor(5.3041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2383 Loss: tensor(28.2319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2384 Loss: tensor(21.6184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2385 Loss: tensor(29.4918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2386 Loss: tensor(48.3894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2387 Loss: tensor(6.9072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2388 Loss: tensor(37.2626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2389 Loss: tensor(5.9898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2390 Loss: tensor(58.2005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2391 Loss: tensor(108.5258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2392 Loss: tensor(12.8719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2393 Loss: tensor(12.3622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2394 Loss: tensor(115.4110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2395 Loss: tensor(12.7921, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2396 Loss: tensor(5.5742, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2397 Loss: tensor(16.4616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2398 Loss: tensor(7.2066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2399 Loss: tensor(13.6419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2400 Loss: tensor(3.5371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2401 Loss: tensor(5.7733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2402 Loss: tensor(7.6132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2403 Loss: tensor(11.5012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2404 Loss: tensor(52.2817, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2405 Loss: tensor(168.6958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2406 Loss: tensor(14.7260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2407 Loss: tensor(10.0304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2408 Loss: tensor(92.6356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2409 Loss: tensor(30.4504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2410 Loss: tensor(16.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2411 Loss: tensor(93.1039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2412 Loss: tensor(16.2334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2413 Loss: tensor(64.9794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2414 Loss: tensor(6.3582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2415 Loss: tensor(4.6435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2416 Loss: tensor(32.6162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2417 Loss: tensor(24.0115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2418 Loss: tensor(125.9223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2419 Loss: tensor(4.0986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2420 Loss: tensor(37.5009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2421 Loss: tensor(24.4029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2422 Loss: tensor(89.5718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2423 Loss: tensor(27.4096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2424 Loss: tensor(11.2562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2425 Loss: tensor(46.6120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2426 Loss: tensor(5.2763, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2427 Loss: tensor(10.8242, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2428 Loss: tensor(7.4607, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2429 Loss: tensor(4.8461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2430 Loss: tensor(114.3401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2431 Loss: tensor(8.9046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2432 Loss: tensor(263.4832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2433 Loss: tensor(32.2078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2434 Loss: tensor(141.7176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2435 Loss: tensor(19.4476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2436 Loss: tensor(95.5356, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2437 Loss: tensor(28.0995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2438 Loss: tensor(6.8364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2439 Loss: tensor(48.3494, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2440 Loss: tensor(17.7471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2441 Loss: tensor(7.3188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2442 Loss: tensor(12.3778, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2443 Loss: tensor(7.0101, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2444 Loss: tensor(9.3583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2445 Loss: tensor(3.7833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2446 Loss: tensor(3.7919, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2447 Loss: tensor(48.4157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2448 Loss: tensor(22.9312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2449 Loss: tensor(31.1408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2450 Loss: tensor(5.9605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2451 Loss: tensor(15.8848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2452 Loss: tensor(27.8608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2453 Loss: tensor(6.5057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2454 Loss: tensor(37.2599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2455 Loss: tensor(135.3680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2456 Loss: tensor(5.0680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2457 Loss: tensor(7.9622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2458 Loss: tensor(8.5369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2459 Loss: tensor(16.3764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2460 Loss: tensor(1506.6394, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2461 Loss: tensor(10.3222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2462 Loss: tensor(8.3383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2463 Loss: tensor(14.7319, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2464 Loss: tensor(49.5660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2465 Loss: tensor(291.6890, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2466 Loss: tensor(28.3687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2467 Loss: tensor(17.9713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2468 Loss: tensor(63.1191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2469 Loss: tensor(119.1611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2470 Loss: tensor(5.2666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2471 Loss: tensor(118.4258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2472 Loss: tensor(5.1220, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2473 Loss: tensor(35.5723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2474 Loss: tensor(6.4845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2475 Loss: tensor(5.6948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2476 Loss: tensor(4.8568, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2477 Loss: tensor(527.0925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2478 Loss: tensor(16.3765, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2479 Loss: tensor(42.0314, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2480 Loss: tensor(10.1315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2481 Loss: tensor(29.5915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2482 Loss: tensor(18.7478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2483 Loss: tensor(8.9223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2484 Loss: tensor(46.3325, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2485 Loss: tensor(27.6310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2486 Loss: tensor(36.2598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2487 Loss: tensor(8.7652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2488 Loss: tensor(59.1591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2489 Loss: tensor(78.1014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2490 Loss: tensor(66.2751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2491 Loss: tensor(25.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2492 Loss: tensor(17.8207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2493 Loss: tensor(24.8932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2494 Loss: tensor(77.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2495 Loss: tensor(38.6095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2496 Loss: tensor(10.1297, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2497 Loss: tensor(10.4975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2498 Loss: tensor(90.5327, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2499 Loss: tensor(43.9235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2500 Loss: tensor(28.1315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2501 Loss: tensor(5.8332, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2502 Loss: tensor(5.2975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2503 Loss: tensor(26.3518, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2504 Loss: tensor(664.9965, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2505 Loss: tensor(22.6798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2506 Loss: tensor(263.4918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2507 Loss: tensor(14.7078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2508 Loss: tensor(21.8034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2509 Loss: tensor(10.8211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2510 Loss: tensor(78.4937, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2511 Loss: tensor(48.9808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2512 Loss: tensor(10.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2513 Loss: tensor(13.5831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2514 Loss: tensor(497.4295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2515 Loss: tensor(13.6686, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2516 Loss: tensor(44.5429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2517 Loss: tensor(8.5514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2518 Loss: tensor(125.9205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2519 Loss: tensor(28.3681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2520 Loss: tensor(36.9085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2521 Loss: tensor(5.5223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2522 Loss: tensor(12.4659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2523 Loss: tensor(13.8587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2524 Loss: tensor(8.9078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2525 Loss: tensor(17.9698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2526 Loss: tensor(73.5070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2527 Loss: tensor(16.3914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2528 Loss: tensor(10.9750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2529 Loss: tensor(11.4150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2530 Loss: tensor(57.5378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2531 Loss: tensor(32.0714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2532 Loss: tensor(18.7044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2533 Loss: tensor(22.5626, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2534 Loss: tensor(22.0307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2535 Loss: tensor(46.5778, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2536 Loss: tensor(29.3972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2537 Loss: tensor(127.2882, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2538 Loss: tensor(12.8042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2539 Loss: tensor(3.5350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2540 Loss: tensor(27.4148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2541 Loss: tensor(6.9933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2542 Loss: tensor(4.7768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2543 Loss: tensor(4.4275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2544 Loss: tensor(10.5646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2545 Loss: tensor(5.3093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2546 Loss: tensor(6.2485, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2547 Loss: tensor(17.9650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2548 Loss: tensor(56.8975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2549 Loss: tensor(8.5429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2550 Loss: tensor(26.3589, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2551 Loss: tensor(6.2618, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2552 Loss: tensor(35.0174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2553 Loss: tensor(33.1433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2554 Loss: tensor(8.5390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2555 Loss: tensor(18.9051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2556 Loss: tensor(4.8567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2557 Loss: tensor(56.5581, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2558 Loss: tensor(16.3932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2559 Loss: tensor(15.9610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2560 Loss: tensor(4.7736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2561 Loss: tensor(23.2090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2562 Loss: tensor(60.6490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2563 Loss: tensor(55.7013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2564 Loss: tensor(64.4577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2565 Loss: tensor(38.6396, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2566 Loss: tensor(14.7261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2567 Loss: tensor(114.0129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2568 Loss: tensor(11.4989, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2569 Loss: tensor(32.0358, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2570 Loss: tensor(48.4066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2571 Loss: tensor(115.3344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2572 Loss: tensor(9.7534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2573 Loss: tensor(28.3408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2574 Loss: tensor(17.9715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2575 Loss: tensor(186.8510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2576 Loss: tensor(54.5149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2577 Loss: tensor(234.0331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2578 Loss: tensor(43.7008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2579 Loss: tensor(1506.6277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2580 Loss: tensor(8.6638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2581 Loss: tensor(40.5133, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2582 Loss: tensor(37.2365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2583 Loss: tensor(1711.1029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2584 Loss: tensor(20.6000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2585 Loss: tensor(10.3138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2586 Loss: tensor(168.7264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2587 Loss: tensor(48.9402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2588 Loss: tensor(8.1269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2589 Loss: tensor(7.6085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2590 Loss: tensor(16.0149, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2591 Loss: tensor(14.3395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2592 Loss: tensor(28.1681, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2593 Loss: tensor(10.1285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2594 Loss: tensor(7.6988, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2595 Loss: tensor(17.9661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2596 Loss: tensor(15.1756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2597 Loss: tensor(7.2565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2598 Loss: tensor(39.2421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2599 Loss: tensor(14.4985, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2600 Loss: tensor(26.1257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2601 Loss: tensor(32.7815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2602 Loss: tensor(12.8972, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2603 Loss: tensor(87.2524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2604 Loss: tensor(10.8027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2605 Loss: tensor(7.4578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2606 Loss: tensor(6.1671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2607 Loss: tensor(11.7452, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2608 Loss: tensor(68.2859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2609 Loss: tensor(77.4019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2610 Loss: tensor(7.2138, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2611 Loss: tensor(9.8583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2612 Loss: tensor(60.7400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2613 Loss: tensor(5.6978, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2614 Loss: tensor(59.8997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2615 Loss: tensor(9.1742, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2616 Loss: tensor(37.2598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2617 Loss: tensor(9.4531, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2618 Loss: tensor(50.1512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2619 Loss: tensor(19.1762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2620 Loss: tensor(17.0264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2621 Loss: tensor(52.0215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2622 Loss: tensor(38.5583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2623 Loss: tensor(87.8504, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2624 Loss: tensor(66.3945, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2625 Loss: tensor(28.1829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2626 Loss: tensor(19.4426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2627 Loss: tensor(32.7951, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2628 Loss: tensor(84.2335, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2629 Loss: tensor(19.2914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2630 Loss: tensor(8.1434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2631 Loss: tensor(6.3639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2632 Loss: tensor(49.6330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2633 Loss: tensor(97.7930, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2634 Loss: tensor(125.5899, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2635 Loss: tensor(99.1858, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2636 Loss: tensor(5.8332, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2637 Loss: tensor(10.6964, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2638 Loss: tensor(14.3371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2639 Loss: tensor(19.0901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2640 Loss: tensor(16.8807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2641 Loss: tensor(16.3787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2642 Loss: tensor(66.3772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2643 Loss: tensor(8.3468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2644 Loss: tensor(4.1123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2645 Loss: tensor(60.2153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2646 Loss: tensor(26.3037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2647 Loss: tensor(141.5695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2648 Loss: tensor(24.0211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2649 Loss: tensor(10.7843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2650 Loss: tensor(24.7018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2651 Loss: tensor(43.3609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2652 Loss: tensor(8.6358, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2653 Loss: tensor(5.2663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2654 Loss: tensor(20.6173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2655 Loss: tensor(53.4002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2656 Loss: tensor(897.8381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2657 Loss: tensor(19.8247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2658 Loss: tensor(38.5364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2659 Loss: tensor(125.3215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2660 Loss: tensor(6.8076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2661 Loss: tensor(6.8180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2662 Loss: tensor(12.3869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2663 Loss: tensor(5.8410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2664 Loss: tensor(33.6569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2665 Loss: tensor(11.2750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2666 Loss: tensor(12.6755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2667 Loss: tensor(9.3438, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2668 Loss: tensor(497.6199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2669 Loss: tensor(16.2233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2670 Loss: tensor(6.8073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2671 Loss: tensor(22.2069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2672 Loss: tensor(3.3440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2673 Loss: tensor(4.4221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2674 Loss: tensor(24.0308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2675 Loss: tensor(56.2922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2676 Loss: tensor(30.7878, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2677 Loss: tensor(72.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2678 Loss: tensor(44.5414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2679 Loss: tensor(44.5510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2680 Loss: tensor(125.9544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2681 Loss: tensor(5.6238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2682 Loss: tensor(12.0641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2683 Loss: tensor(14.6140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2684 Loss: tensor(8.1912, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2685 Loss: tensor(127.2797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2686 Loss: tensor(3.4370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2687 Loss: tensor(8.8721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2688 Loss: tensor(72.4345, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2689 Loss: tensor(41.1166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2690 Loss: tensor(9.7713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2691 Loss: tensor(38.6537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2692 Loss: tensor(12.4813, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2693 Loss: tensor(26.2995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2694 Loss: tensor(16.3815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2695 Loss: tensor(161.8632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2696 Loss: tensor(8.6179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2697 Loss: tensor(620.2163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2698 Loss: tensor(108.5839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2699 Loss: tensor(3286.1409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2700 Loss: tensor(90.5449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2701 Loss: tensor(30.2831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2702 Loss: tensor(20.3418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2703 Loss: tensor(22.3369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2704 Loss: tensor(127.2333, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2705 Loss: tensor(8.0228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2706 Loss: tensor(8.8780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2707 Loss: tensor(29.5053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2708 Loss: tensor(19.1435, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2709 Loss: tensor(18.1125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2710 Loss: tensor(83.0842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2711 Loss: tensor(134.9441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2712 Loss: tensor(20.6140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2713 Loss: tensor(7.2574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2714 Loss: tensor(72.3925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2715 Loss: tensor(38.2372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2716 Loss: tensor(9.7818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2717 Loss: tensor(48.4106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2718 Loss: tensor(24.8657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2719 Loss: tensor(7.5557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2720 Loss: tensor(872.2215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2721 Loss: tensor(8.8812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2722 Loss: tensor(18.7109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2723 Loss: tensor(14.6929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2724 Loss: tensor(41.2494, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2725 Loss: tensor(8.9243, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2726 Loss: tensor(114.3154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2727 Loss: tensor(72.1015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2728 Loss: tensor(74.5802, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2729 Loss: tensor(12.3640, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2730 Loss: tensor(24.1837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2731 Loss: tensor(24.0732, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2732 Loss: tensor(43.5478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2733 Loss: tensor(7.4534, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2734 Loss: tensor(87.8444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2735 Loss: tensor(17.5574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2736 Loss: tensor(30.1445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2737 Loss: tensor(44.6888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2738 Loss: tensor(365.6461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2739 Loss: tensor(12.7840, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2740 Loss: tensor(22.2144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2741 Loss: tensor(12.8467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2742 Loss: tensor(9.3768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2743 Loss: tensor(106.8737, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2744 Loss: tensor(37.2527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2745 Loss: tensor(7.4664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2746 Loss: tensor(8.0161, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2747 Loss: tensor(841.7820, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2748 Loss: tensor(6.5043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2749 Loss: tensor(15.5310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2750 Loss: tensor(31.9937, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2751 Loss: tensor(5.5270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2752 Loss: tensor(41.9113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2753 Loss: tensor(10.9838, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2754 Loss: tensor(64.4624, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2755 Loss: tensor(18.4553, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2756 Loss: tensor(54.4900, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2757 Loss: tensor(21.5976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2758 Loss: tensor(6.1746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2759 Loss: tensor(10.1224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2760 Loss: tensor(67.8701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2761 Loss: tensor(5.6323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2762 Loss: tensor(16.0219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2763 Loss: tensor(170.7799, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2764 Loss: tensor(48.9037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2765 Loss: tensor(70.5724, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2766 Loss: tensor(5.2890, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2767 Loss: tensor(14.2317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2768 Loss: tensor(10.8993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2769 Loss: tensor(12.3955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2770 Loss: tensor(10.3232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2771 Loss: tensor(40.3368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2772 Loss: tensor(98.1991, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2773 Loss: tensor(111.7689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2774 Loss: tensor(7.1510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2775 Loss: tensor(5.6448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2776 Loss: tensor(8.3574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2777 Loss: tensor(7.3206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2778 Loss: tensor(87.8556, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2779 Loss: tensor(44.7585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2780 Loss: tensor(38.5197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2781 Loss: tensor(14.7418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2782 Loss: tensor(99.1585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2783 Loss: tensor(9.7533, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2784 Loss: tensor(18.4111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2785 Loss: tensor(263.5621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2786 Loss: tensor(13.2267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2787 Loss: tensor(30.4482, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2788 Loss: tensor(21.1370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2789 Loss: tensor(1796.7266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2790 Loss: tensor(57.0447, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2791 Loss: tensor(729.9976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2792 Loss: tensor(77.0755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2793 Loss: tensor(35.0264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2794 Loss: tensor(135.5884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2795 Loss: tensor(33.1594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2796 Loss: tensor(84.6035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2797 Loss: tensor(59.8502, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2798 Loss: tensor(1506.6030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2799 Loss: tensor(14.1558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2800 Loss: tensor(44.7646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2801 Loss: tensor(37.4821, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2802 Loss: tensor(21.5056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2803 Loss: tensor(897.8216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2804 Loss: tensor(26.2708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2805 Loss: tensor(38.5309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2806 Loss: tensor(22.5778, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2807 Loss: tensor(4.4569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2808 Loss: tensor(30.3741, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2809 Loss: tensor(10.6453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2810 Loss: tensor(11.9250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2811 Loss: tensor(17.4692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2812 Loss: tensor(16.9166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2813 Loss: tensor(27.6843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2814 Loss: tensor(41.9110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2815 Loss: tensor(62.2832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2816 Loss: tensor(40.2051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2817 Loss: tensor(7.1595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2818 Loss: tensor(17.9620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2819 Loss: tensor(12.4760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2820 Loss: tensor(64.4137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2821 Loss: tensor(871.9744, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2822 Loss: tensor(31.9331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2823 Loss: tensor(15.5584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2824 Loss: tensor(841.6421, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2825 Loss: tensor(17.8647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2826 Loss: tensor(48.4090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2827 Loss: tensor(48.8815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2828 Loss: tensor(95.6097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2829 Loss: tensor(38.2303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2830 Loss: tensor(3.3493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2831 Loss: tensor(10.5021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2832 Loss: tensor(14.5103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2833 Loss: tensor(72.9372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2834 Loss: tensor(32.4805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2835 Loss: tensor(12.4563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2836 Loss: tensor(28.3658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2837 Loss: tensor(497.6414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2838 Loss: tensor(73.4132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2839 Loss: tensor(8.8598, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2840 Loss: tensor(10.3236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2841 Loss: tensor(9.5805, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2842 Loss: tensor(41.9330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2843 Loss: tensor(5.8292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2844 Loss: tensor(6.1474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2845 Loss: tensor(19.8694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2846 Loss: tensor(7.1961, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2847 Loss: tensor(11.9207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2848 Loss: tensor(2191.3269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2849 Loss: tensor(16.2389, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2850 Loss: tensor(12.7976, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2851 Loss: tensor(8.5462, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2852 Loss: tensor(169.4800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2853 Loss: tensor(10.8168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2854 Loss: tensor(13.6851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2855 Loss: tensor(897.6843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2856 Loss: tensor(114.3666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2857 Loss: tensor(12.4447, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2858 Loss: tensor(21.8021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2859 Loss: tensor(8.7691, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2860 Loss: tensor(30.7746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2861 Loss: tensor(10.3771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2862 Loss: tensor(9.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2863 Loss: tensor(42.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2864 Loss: tensor(30.2784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2865 Loss: tensor(26.0211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2866 Loss: tensor(32.6198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2867 Loss: tensor(18.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2868 Loss: tensor(24.0126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2869 Loss: tensor(62.6861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2870 Loss: tensor(25.0546, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2871 Loss: tensor(8.0223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2872 Loss: tensor(57.9200, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2873 Loss: tensor(19.0815, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2874 Loss: tensor(8.9993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2875 Loss: tensor(7.4442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2876 Loss: tensor(5.2787, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2877 Loss: tensor(47.6475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2878 Loss: tensor(70.1004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2879 Loss: tensor(32.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2880 Loss: tensor(3.7884, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2881 Loss: tensor(74.1119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2882 Loss: tensor(4412.5195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2883 Loss: tensor(100.1952, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2884 Loss: tensor(33.6394, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2885 Loss: tensor(322.2991, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2886 Loss: tensor(12.3511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2887 Loss: tensor(30.0129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2888 Loss: tensor(6.9312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2889 Loss: tensor(5.2831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2890 Loss: tensor(155.6881, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2891 Loss: tensor(168.7006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2892 Loss: tensor(46.3470, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2893 Loss: tensor(6.8769, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2894 Loss: tensor(31.1509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2895 Loss: tensor(10.6861, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2896 Loss: tensor(7.6721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2897 Loss: tensor(22.0249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2898 Loss: tensor(8.5426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2899 Loss: tensor(56.5466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2900 Loss: tensor(8.1092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2901 Loss: tensor(168.7081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2902 Loss: tensor(43.6004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2903 Loss: tensor(19.7168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2904 Loss: tensor(15.1177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2905 Loss: tensor(3285.5542, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2906 Loss: tensor(19.1751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2907 Loss: tensor(4.2402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2908 Loss: tensor(62.1870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2909 Loss: tensor(28.0701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2910 Loss: tensor(10.9377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2911 Loss: tensor(18.4684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2912 Loss: tensor(16.2178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2913 Loss: tensor(96.2856, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2914 Loss: tensor(13.8481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2915 Loss: tensor(65.1012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2916 Loss: tensor(16.2199, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2917 Loss: tensor(55.8625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2918 Loss: tensor(7.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2919 Loss: tensor(40.4599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2920 Loss: tensor(17.4601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2921 Loss: tensor(33.1708, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2922 Loss: tensor(28.8059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2923 Loss: tensor(8.8606, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2924 Loss: tensor(96.0244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2925 Loss: tensor(26.1597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2926 Loss: tensor(2191.5029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2927 Loss: tensor(6.8645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2928 Loss: tensor(89.1517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2929 Loss: tensor(25.0960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2930 Loss: tensor(22.0973, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2931 Loss: tensor(6.2608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2932 Loss: tensor(29.3825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2933 Loss: tensor(12.3697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2934 Loss: tensor(60.7543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2935 Loss: tensor(372.3633, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2936 Loss: tensor(6.9364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2937 Loss: tensor(66.6768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2938 Loss: tensor(17.5559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2939 Loss: tensor(22.0439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2940 Loss: tensor(31.9065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2941 Loss: tensor(19.3381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2942 Loss: tensor(4.7416, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2943 Loss: tensor(20.3113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2944 Loss: tensor(6.7794, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2945 Loss: tensor(6.1492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2946 Loss: tensor(70.4187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2947 Loss: tensor(176.0946, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2948 Loss: tensor(8.5446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2949 Loss: tensor(20.9655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2950 Loss: tensor(20.2776, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2951 Loss: tensor(80.0722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2952 Loss: tensor(18.7462, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2953 Loss: tensor(497.2405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2954 Loss: tensor(44.0244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2955 Loss: tensor(38.6038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2956 Loss: tensor(170.8738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2957 Loss: tensor(7.1588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2958 Loss: tensor(16.6010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2959 Loss: tensor(233.8024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2960 Loss: tensor(28.3772, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2961 Loss: tensor(31.7631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2962 Loss: tensor(56.5809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2963 Loss: tensor(22.5854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2964 Loss: tensor(44.5528, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2965 Loss: tensor(88.9191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2966 Loss: tensor(161.1866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2967 Loss: tensor(10.4942, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2968 Loss: tensor(44.6570, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2969 Loss: tensor(78.0440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2970 Loss: tensor(31.7477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2971 Loss: tensor(4.4129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2972 Loss: tensor(5.6498, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2973 Loss: tensor(17.9754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2974 Loss: tensor(6.7260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2975 Loss: tensor(1710.8384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2976 Loss: tensor(36.0968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2977 Loss: tensor(14.7558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2978 Loss: tensor(4.6361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2979 Loss: tensor(15.5323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2980 Loss: tensor(4.7764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2981 Loss: tensor(4.1669, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2982 Loss: tensor(34.1424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2983 Loss: tensor(83.0490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2984 Loss: tensor(5.8403, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2985 Loss: tensor(40.3755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2986 Loss: tensor(90.8722, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2987 Loss: tensor(24.4843, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2988 Loss: tensor(345.1740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2989 Loss: tensor(119.8014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2990 Loss: tensor(13.2205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2991 Loss: tensor(322.4136, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2992 Loss: tensor(8.5460, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2993 Loss: tensor(78.5213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2994 Loss: tensor(97.7632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2995 Loss: tensor(96.4752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2996 Loss: tensor(53.4368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2997 Loss: tensor(8.9148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2998 Loss: tensor(8.8203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2999 Loss: tensor(16.4460, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 3000 Loss: tensor(95.4578, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Train with sampled data\n",
    "epoch_num = 3000\n",
    "lr = 0.001\n",
    "gamma = 0.5\n",
    "\n",
    "K = 100\n",
    "s = 0.0004\n",
    "step_size = 100\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "# G = ResidualLearning()\n",
    "G = U_net(1,1).to(device)\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/model3/40_160_unet/lr{lr}_gamma{gamma}_stepsize{step_size}_K{K}_llsigma_{ll_sigma}_psigma_{prior_sigma}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    b_high, low_res = sample_data()\n",
    "    b_high = torch.tensor(b_high).to(torch.float32).to(device)\n",
    "    low_res = torch.tensor(low_res).to(torch.float32).to(device)\n",
    "    \n",
    "    posterior_initial = sample_p_0(low_res)\n",
    "    posterior_final = ula_posterior_preconditioner(posterior_initial, b_high, low_res, G)\n",
    "\n",
    "    optG.zero_grad()\n",
    "    \n",
    "    downscaled = F.interpolate(posterior_final.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(1,N_low,N_low)\n",
    "    out = G(downscaled.reshape(1,1,N_low,N_low)).reshape(1,N_low,N_low) + downscaled\n",
    "    loss = mse(out,low_res.reshape(1,N_low,N_low))\n",
    "\n",
    "    # total_loss += loss\n",
    "    # total_loss /= 8\n",
    "\n",
    "    loss.backward()\n",
    "    optG.step()\n",
    "    \n",
    "    if loss < minimum_loss:\n",
    "        save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "        minimum_loss = loss\n",
    "            \n",
    "    if epoch%100 == 0:\n",
    "        save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "    \n",
    "    save_model(dir_name, epoch, 'current_epoch', r_scheduleG, G, optG)\n",
    "    loss_track.append(loss.cpu().data.numpy())\n",
    "    np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "    \n",
    "    print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upscale By 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_low = 21\n",
    "N_high = 121\n",
    "scale = 6\n",
    "\n",
    "h_low = 1/(N_low-1)\n",
    "x_low = np.arange(0,1.0001,h_low)\n",
    "y_low = np.arange(0,1.0001,h_low)\n",
    "\n",
    "h_high = 1/(N_high-1)\n",
    "x_high = np.arange(0,1.0001,h_high)\n",
    "y_high = np.arange(0,1.0001,h_high)\n",
    "\n",
    "A_high = create_A(N_high)\n",
    "A_low = create_A(N_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for prior variance\n",
    "prior_sigma = 0.002\n",
    "ll_sigma = 0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prior variance\n",
    "G = np.eye(N_high**2) * prior_sigma**2\n",
    "G_inverse = np.eye(N_high**2) * (1/prior_sigma**2)\n",
    "\n",
    "# Turn matrices to tensors\n",
    "G = torch.tensor(G).to(torch.float32).to(device)\n",
    "G_inverse = torch.tensor(G_inverse).to(torch.float32).to(device)\n",
    "A_high = torch.tensor(create_A(N_high)).to(torch.float32).to(device)\n",
    "\n",
    "# Store sparse matrices as sparse tensor\n",
    "A_high = A_high.to_sparse()\n",
    "G = G.to_sparse()\n",
    "G_inverse = G_inverse.to_sparse()\n",
    "operator = torch.spmm(A_high.T,G_inverse).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFromH5File4(\"/home/pz281@ad.eng.cam.ac.uk/mnt/PhD/Pro_Down_SR/data/21_121_low_forcing.h5\")\n",
    "\n",
    "trainset = random.sample(range(0, 128), 100)\n",
    "testset = [i for i in range(0,128) if i not in trainset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    coefficient = random.sample(trainset,1)[0]\n",
    "    forcing = dataset[coefficient][0]\n",
    "    lr = dataset[coefficient][1]\n",
    "    \n",
    "    return forcing, lr\n",
    "\n",
    "\n",
    "def sample_p_0():\n",
    "    # Randomly sampling for initialisation of the Langevin dynamics\n",
    "    # prior = torch.randn(*[batch_size,1,20,20]).to(device)\n",
    "    \n",
    "    # Set the u_low_mean to the initialisation of the Langevin dynamics\n",
    "    posterior_initial = torch.randn([N_high,N_high]).to(torch.float32)\n",
    "    posterior_initial = torch.tensor(posterior_initial).to(device).to(torch.float32)\n",
    "    \n",
    "    return posterior_initial\n",
    "\n",
    "    \n",
    "def ula_posterior_preconditioner(z, b_high, x, G):\n",
    "    \"\"\"\n",
    "    Langevin dynamics with preconditioner\n",
    "    \"\"\"\n",
    "    z = z.clone().detach().requires_grad_(True)\n",
    "    for i in range(K):\n",
    "        # Grad log-likelihood\n",
    "        downscaled = F.interpolate(z.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(N_low,N_low)\n",
    "        x_hat = downscaled + G(downscaled.reshape(1,N_low,N_low)).reshape(N_low,N_low)\n",
    "        log_likelihood = (-1/(2*math.pow(ll_sigma, 2)) * torch.matmul((x-x_hat).reshape(1,N_low**2),(x-x_hat).reshape(N_low**2,1)))\n",
    "        grad_ll = torch.autograd.grad(log_likelihood, z)[0]\n",
    "\n",
    "        # Grad prior\n",
    "        difference = torch.spmm(A_high,z.reshape(N_high*N_high,1)) - b_high.reshape(N_high**2,1)\n",
    "        # log_prior = - 0.5 * difference.T @ G_inverse @ difference\n",
    "        # grad_log_prior = torch.autograd.grad(log_prior, z)[0]\n",
    "        grad_log_prior = (- torch.spmm(operator,difference)).reshape(N_high,N_high)\n",
    "        \n",
    "        # Random noise term\n",
    "        W = torch.randn(*[N_high,N_high]).to(device)\n",
    "        # random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\n",
    "        \n",
    "        z = z + 0.5 * s ** 2 * grad_log_prior + 0.5 * s ** 2 * grad_ll + s * W\n",
    "        # chains_evolution.append(z.cpu().data.numpy())   \n",
    "           \n",
    "    return z.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-03 13:45:19,851 : Training for 1000 epoches and learning rate is 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12620/2123801182.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior_initial = torch.tensor(posterior_initial).to(device).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: tensor(4.8323, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 2 Loss: tensor(1.6451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 3 Loss: tensor(5.1077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 4 Loss: tensor(2.2748, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 5 Loss: tensor(0.8231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 6 Loss: tensor(2.1439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 7 Loss: tensor(0.5367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 8 Loss: tensor(0.9620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 9 Loss: tensor(5.6040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 10 Loss: tensor(2.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 11 Loss: tensor(15.0155, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 12 Loss: tensor(0.7064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 13 Loss: tensor(0.5590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch: 14 Loss: tensor(7.4551, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m low_res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(low_res)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m posterior_initial \u001b[38;5;241m=\u001b[39m sample_p_0()\n\u001b[0;32m---> 31\u001b[0m posterior_final \u001b[38;5;241m=\u001b[39m \u001b[43mula_posterior_preconditioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposterior_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_high\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m optG\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m downscaled \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(posterior_final\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,N_high,N_high),(N_low,N_low))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,N_low,N_low)\n",
      "Cell \u001b[0;32mIn[34], line 42\u001b[0m, in \u001b[0;36mula_posterior_preconditioner\u001b[0;34m(z, b_high, x, G)\u001b[0m\n\u001b[1;32m     39\u001b[0m     W \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39m[N_high,N_high])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# random = torch.matmul(G_sqrt,W.reshape(N_high**2,1)).reshape(N_high,N_high)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_log_prior\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m s \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m grad_ll \u001b[38;5;241m+\u001b[39m s \u001b[38;5;241m*\u001b[39m W\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# chains_evolution.append(z.cpu().data.numpy())   \u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train with sampled data\n",
    "epoch_num = 1000\n",
    "lr = 0.005\n",
    "gamma = 0.5\n",
    "step_size = 30\n",
    "minimum_loss = float('inf')\n",
    "loss_track = []\n",
    "\n",
    "K = 10000\n",
    "s = 0.0004\n",
    "\n",
    "G = ResidualLearning()\n",
    "G.apply(weights_init_xavier).to(device)\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "optG = torch.optim.Adam(G.parameters(), lr = lr, weight_decay=0, betas=(0.5, 0.999))\n",
    "r_scheduleG = torch.optim.lr_scheduler.StepLR(optG, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Logger info\n",
    "dir_name = f'models/model3/21_121/lr{lr}_gamma{gamma}_stepsize{step_size}_K{K}'\n",
    "makedir(dir_name)\n",
    "logger = setup_logging('job0', dir_name, console=True)\n",
    "logger.info(f'Training for {epoch_num} epoches and learning rate is {lr}')\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    b_high, low_res = sample_data()\n",
    "    b_high = torch.tensor(b_high).to(torch.float32).to(device)\n",
    "    low_res = torch.tensor(low_res).to(torch.float32).to(device)\n",
    "    \n",
    "    posterior_initial = sample_p_0()\n",
    "    posterior_final = ula_posterior_preconditioner(posterior_initial, b_high, low_res, G)\n",
    "\n",
    "    optG.zero_grad()\n",
    "    \n",
    "    downscaled = F.interpolate(posterior_final.reshape(1,1,N_high,N_high),(N_low,N_low)).reshape(1,N_low,N_low)\n",
    "    out = G(downscaled.reshape(1,N_low,N_low)) + downscaled\n",
    "    loss = mse(out,low_res.reshape(1,N_low,N_low))\n",
    "        \n",
    "    loss.backward()\n",
    "    optG.step()\n",
    "    \n",
    "    if loss < minimum_loss:\n",
    "        save_model(dir_name, epoch, 'best_model', r_scheduleG, G, optG)\n",
    "        minimum_loss = loss\n",
    "            \n",
    "    if epoch%100 == 0:\n",
    "        save_model(dir_name, epoch, 'model_epoch_{}'.format(epoch), r_scheduleG, G, optG)\n",
    "        \n",
    "    save_model(dir_name, epoch, 'current_epoch', r_scheduleG, G, optG)\n",
    "        \n",
    "    loss_track.append(loss.cpu().data.numpy())\n",
    "    np.save(f'{dir_name}/chains/loss_curve.npy', np.array(loss_track))\n",
    "    \n",
    "    print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "\n",
    "    r_scheduleG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
