{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS']='2'\n",
    "os.environ['LD_LIBRARY_PATH']=''\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pengyu.zhang/project/superres/ProbSR/Experiment3\n"
     ]
    }
   ],
   "source": [
    "%cd /home/pengyu.zhang/project/superres/ProbSR/Experiment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import *\n",
    "from scipy.linalg import sqrtm\n",
    "from downscaling import *\n",
    "from utils import *\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [5:57:42<00:00, 268.28s/it]  \n"
     ]
    }
   ],
   "source": [
    "N_low = 15\n",
    "N_high = 60\n",
    "scale = 4\n",
    "    \n",
    "for i in tqdm(range(80)):\n",
    "    a = random.uniform(-4,4)\n",
    "    b = random.uniform(-4,4)\n",
    "    c = random.uniform(-4,4)\n",
    "    d = random.uniform(-2,2)\n",
    "    w_low = generate_data(N_low,a,b,c,d)[0]\n",
    "    w_high = generate_data(N_high,a,b,c,d)[0]\n",
    "    w_high_tensor = torch.tensor(w_high).to(torch.float32)\n",
    "    w_low_tensor = torch.tensor(w_low).to(torch.float32)\n",
    "    downscaled = F.interpolate(w_high_tensor.reshape(1,1,N_high,N_high,N_high),(N_low,N_low,N_low)).reshape(N_low,N_low,N_low)\n",
    "    residual = (w_low_tensor-downscaled).numpy()\n",
    "    \n",
    "    if i == 0:\n",
    "        total_low = w_low.reshape(1,N_low,N_low,N_low)\n",
    "        total_high = w_high.reshape(1,N_high,N_high,N_high)\n",
    "        total_residual = residual.reshape(1,N_low,N_low,N_low)\n",
    "    else:\n",
    "        total_low = np.concatenate([total_low,w_low.reshape(1,N_low,N_low,N_low)],axis=0)\n",
    "        total_high = np.concatenate([total_high,w_high.reshape(1,N_high,N_high,N_high)],axis=0)\n",
    "        total_residual = np.concatenate([total_residual,residual.reshape(1,N_low,N_low,N_low)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data/DownBy4_15_60_bicubic.h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"high_res\",  data=total_high)\n",
    "    hf.create_dataset(\"low_res\",  data=total_low)\n",
    "    hf.create_dataset(\"residual\", data=total_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_forcing_term(20,8,3,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [18:44<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "N_low = 16\n",
    "N_high = 64\n",
    "scale = 4\n",
    "\n",
    "# Code downscaling matrix\n",
    "'''H = np.zeros((N_low*N_low, N_high*N_high))\n",
    "\n",
    "submatrix = np.zeros((N_low,N_high))\n",
    "for i in range(N_low):\n",
    "    submatrix[i,scale*i] = 1\n",
    "    \n",
    "for j in range(N_low):\n",
    "    H[N_low*j:N_low*(j+1),N_high*scale*j:N_high*(scale*j+1)] = submatrix'''\n",
    "    \n",
    "for i in tqdm(range(1000)):\n",
    "    a = random.uniform(-4,4)\n",
    "    b = random.uniform(-4,4)\n",
    "    c = random.uniform(-4,4)\n",
    "    d = random.uniform(-2,2)\n",
    "    w_low = generate_data(N_low,a,b,c,d)[0]\n",
    "    b_high = create_forcing_term(N_high,a,b,c,d)\n",
    "    \n",
    "    if i==0:\n",
    "        total_low = w_low.reshape(1,N_low,N_low,N_low)\n",
    "        total_forcing = b_high.reshape(1,N_high**3,1)\n",
    "    else:\n",
    "        total_low = np.concatenate([total_low,w_low.reshape(1,N_low,N_low,N_low)],axis=0)\n",
    "        total_forcing = np.concatenate([total_forcing,b_high.reshape(1,N_high**3,1)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15, 15, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_low.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data/16_64_low_forcing.h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"low_res\",  data=total_low)\n",
    "    hf.create_dataset(\"forcing\", data=total_forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
